{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7PbDyk1Vds3D+0aw/XiOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angel870326/Monthly-Revenue-Forecasting/blob/main/Function/MonRevForecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3UyvF37PpZp"
      },
      "source": [
        "> 2023.04.08 Ssu-Yun Wang<br/>\n",
        "[Github @angel870326](https://github.com/angel870326)\n",
        "\n",
        "# **Monthly Revenue Forecasting with Random Forest Regressor & XGB Regressor - Model**\n",
        "\n",
        "### Contents\n",
        "\n",
        "##### 4. Functions\n",
        "##### 5. Model Training\n",
        "##### 6. Predicting and Evaluation\n",
        "##### 9. Best and Worst Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.seasonal import STL"
      ],
      "metadata": {
        "id": "QGu9WzMGctsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP1USHnpKYuB"
      },
      "source": [
        "## **4. Functions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QakiMtVvlDQ"
      },
      "outputs": [],
      "source": [
        "# 往前推算月份\n",
        "def back_month(yr: int, mon: int, back: int):\n",
        "    '''\n",
        "    往前推算月份。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    yr: 第t期的年, mon: 第t期的月, back: 往前推算幾個月\n",
        "    '''\n",
        "\n",
        "    # 若當下月份(mon)減除往前期數(b)大於0，即還在同一年內\n",
        "    if mon - back > 0:                         \n",
        "        return str(yr) + '-' + str(mon - back)      # 直接回傳當下年份(yr)，以及當下月份(mon)減除往前期數(back)，所組成的字串\n",
        "    # 不屬於同一年\n",
        "    else:                               \n",
        "        return back_month(yr - 1, mon, back - 12)   # 手動調減一年，並將往前期數(back)減少12個月"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpomeaaOwTe1"
      },
      "outputs": [],
      "source": [
        "# 取得 t-back_most ~ t-1 期的 X 資料\n",
        "def X_months(data: pd.DataFrame, y_yr: int, y_mon: int, back_most: int):\n",
        "    '''\n",
        "    取得 t-back_most ~ t-1 期的 X 資料。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集; y_yr: 第t期的年, y_mon: 第t期的月, back_most: X的最早月份是第t期的往前多少月份\n",
        "    '''\n",
        "\n",
        "    months = []\n",
        "    for b in range(back_most, 0, -1):               # 從 back_most 到 1\n",
        "        months.append(back_month(y_yr, y_mon, b))   # 根據每個往前月份數(b)推算對應年月，儲存進 months 之中\n",
        "    \n",
        "    # 回傳 data 中的這些月份\n",
        "    return data[months]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvre6fxJqIr-"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# 取得起始年月到終止年月的每個年月\n",
        "def month_range(y_start_yr: int, y_start_mon: int, y_end_yr: int, y_end_mon: int):\n",
        "    '''\n",
        "    取得起始年月到終止年月的每個年月。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_start_yr: 起始年, y_start_mon: 起始月, y_end_yr: 終止年, y_end_mon: 終止月\n",
        "    '''\n",
        "\n",
        "    start_ym = str(y_start_yr) + '-' + str(y_start_mon)\n",
        "    \n",
        "    # pd.date_range 中的 end 為終止月的下一個月，因此須將終止年月加 1 個月\n",
        "    if y_end_mon < 12:\n",
        "        end_ym = str(y_end_yr) + '-' + str(y_end_mon + 1)   # 終止月為1-11月時，直接在月份+1\n",
        "    else: \n",
        "        end_ym = str(y_end_yr + 1) + '-' + '1'              # 終止月為12月時，end 設為下一年的1月\n",
        "    \n",
        "    # 生成從起始年月到終止年月的每個年月\n",
        "    month_list = pd.date_range(start=start_ym, end=end_ym, freq='M').to_period('M').strftime('%Y-%m').to_numpy()\n",
        "\n",
        "    return month_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 對 X 做標準化（和 sklearn 的 StandardScaler 公式相同）\n",
        "def standardize_X(data: pd.DataFrame):\n",
        "    '''\n",
        "    對 X 做標準化。\n",
        "\n",
        "    Parameters \n",
        "    ----------\n",
        "    data: X\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    mean, std, std_data\n",
        "    '''\n",
        "    mean = data.mean(axis=1)\n",
        "    std = data.std(axis=1)\n",
        "    std_data = data.apply(lambda row: (row-mean[row.name])/std[row.name], axis=1)\n",
        "    return mean, std, std_data\n",
        "\n",
        "# 以 X 的平均數和標準差對 y 做標準化\n",
        "def standardize_y(mean: pd.Series, std: pd.Series, data: pd.Series):\n",
        "    '''\n",
        "    以 X 的平均數和標準差對 y 做標準化。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mean: X 的平均數, std: X 的標準差, data: y\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    std_data\n",
        "    '''\n",
        "    std_data = []\n",
        "    for i in range(len(data)):\n",
        "        std_data.append((data[i]-mean[i])/std[i])\n",
        "    return std_data\n",
        "\n",
        "# 將標準化的 y 轉回正常值\n",
        "def standardized_y_back(mean: pd.Series, std: pd.Series, std_data: np.array):\n",
        "    '''\n",
        "    將標準化的 y 轉回原始值。\n",
        "\n",
        "    Parameters \n",
        "    ----------\n",
        "    mean: X 的平均數, std: X 的標準差, data: 標準化的 y\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    data\n",
        "    '''\n",
        "    data = []\n",
        "    for i in range(len(std_data)):\n",
        "        data.append(std_data[i] * std[i] + mean[i])\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "UAxT8ToSzMnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwXXzhQZFoRA"
      },
      "outputs": [],
      "source": [
        "# 將資料拆解為 trend, seasonal, residual\n",
        "def decompose_data(data: pd.DataFrame):\n",
        "    '''\n",
        "    將資料拆解為 trend, seasonal, residual，並回傳三個資料集。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    trend, seasonal, residual\n",
        "    '''\n",
        "    trend = pd.DataFrame(index=data.index, columns=[c + '_trend' for c in data.columns], dtype=float)       # 在日期變數後面加上影響因素名稱\n",
        "    seasonal = pd.DataFrame(index=data.index, columns=[c + '_season' for c in data.columns], dtype=float)\n",
        "    residual = pd.DataFrame(index=data.index, columns=[c + '_resid' for c in data.columns], dtype=float)\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        decomposed_row = STL(row.to_numpy(), period=12, seasonal=13).fit()\n",
        "        trend.loc[index] = np.round(decomposed_row.trend, 4)\n",
        "        seasonal.loc[index] = np.round(decomposed_row.seasonal, 4)\n",
        "        residual.loc[index] = np.round(decomposed_row.resid, 4)\n",
        "\n",
        "    # decomposed_data = pd.concat([trend, seasonal, residual], axis=1)\n",
        "\n",
        "    return trend, seasonal, residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wvWltuLNX86"
      },
      "outputs": [],
      "source": [
        "# 取得訓練和測試資料集\n",
        "def get_train_test(data: pd.DataFrame, y_test_yr: int, y_test_mon: int, back_most: int, y_back: int):\n",
        "    '''\n",
        "    取得訓練和測試資料集。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集, y_test_yr: 要預測的年, y_test_mon: 要預測的月, \n",
        "    back_most: X的最早月份是第t期的往前多少月份, \n",
        "    y_back: 訓練資料集的y要比測試資料集的y往前多少月份\n",
        "\n",
        "    Returns \n",
        "    ----------\n",
        "    X_train, y_train, X_test, y_test\n",
        "    '''\n",
        "\n",
        "    # 測試資料\n",
        "    y_test = data[f'{y_test_yr}-{y_test_mon}']\n",
        "    X_test = X_months(data, y_test_yr, y_test_mon, back_most)\n",
        "    # 訓練資料\n",
        "    y_train_ym = back_month(y_test_yr, y_test_mon, y_back)\n",
        "    y_train = data[y_train_ym]\n",
        "    X_train = X_months(data, int(y_train_ym.split(\"-\")[0]), int(y_train_ym.split(\"-\")[1]), back_most)\n",
        "    # 更改X的變數名稱為 t-? 期\n",
        "    X_test.columns = [\"t-\"+str(t) for t in range(back_most, 0, -1)]                                     \n",
        "    X_train.columns = [\"t-\"+str(t) for t in range(back_most, 0, -1)]     \n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDwS7pKujcJY"
      },
      "source": [
        "## **5. Model Training**\n",
        "\n",
        "[RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) & [XGBRegressor](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK_7x3L6i-p2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# Evaluation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "# Model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost.sklearn import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1 Parameter Grid for Grid Search**"
      ],
      "metadata": {
        "id": "TfZ95n_4fEDL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuanmZ74SASz"
      },
      "outputs": [],
      "source": [
        "# Parameter grid for grid search\n",
        "rf_params = {\"n_estimators\": [100], \n",
        "             \"random_state\": [0], \n",
        "             \"n_jobs\": [-1]\n",
        "             }\n",
        "\n",
        "xgb_params = {\"n_estimators\": [100, 250, 500], \n",
        "              \"objective\": ['reg:squarederror'],\n",
        "              \"learning_rate\":[0.1, 0.2],  # usually range from 0.01 to 0.2\n",
        "              \"random_state\": [0],\n",
        "              \"n_jobs\": [-1]\n",
        "             }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.2 訓練單一模型（Random Forest or XGB）**"
      ],
      "metadata": {
        "id": "n2dDeSnCfRuf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_M6SlG0CjrE"
      },
      "outputs": [],
      "source": [
        "# 訓練模型\n",
        "def train_model(modelName, X_train, y_train):\n",
        "    '''\n",
        "    以預先設定好的參數訓練模型。\n",
        "\n",
        "    Parameters\n",
        "    ---------- \n",
        "    modelName: | 'rf' | 'xgb' |, X_train: 訓練資料的X, y_train: 訓練資料的y\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    model\n",
        "    '''\n",
        "    if modelName == 'rf':\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=0, n_jobs=-1) \n",
        "        model.fit(X_train, y_train)\n",
        "    elif modelName == 'xgb':\n",
        "        model = XGBRegressor(n_estimators=500, objective='reg:squarederror', learning_rate=0.1, random_state=0, n_jobs=-1, eval_metric=mean_squared_error) \n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Grid Search 找出最佳模型參數 (Hyperparameters tuned by k-fold cross validation)\n",
        "def search_best_model(modelName, X_train, y_train, cv: int, print_best_params: bool = False):\n",
        "    '''\n",
        "    做 Cross Validation 找出最佳模型參數。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    modelName: | 'rf' | 'xgb' |, X_train: 訓練資料的X, y_train: 訓練資料的y, \n",
        "    cv: K-Fold, \n",
        "    print_best_params: 是否要印出最佳模型參數（預設為否）\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    best_model\n",
        "    '''\n",
        "    if modelName == 'rf':\n",
        "        base_estimator = RandomForestRegressor()\n",
        "        params = rf_params.copy()\n",
        "    elif modelName == 'xgb':\n",
        "        base_estimator = XGBRegressor()\n",
        "        params = xgb_params.copy()\n",
        "\n",
        "    search = GridSearchCV(base_estimator, params, scoring='neg_root_mean_squared_error', cv=cv, refit=True, n_jobs=-1)\n",
        "    search.fit(X_train, y_train)          # 對訓練資料做 cross validation，找出最佳模型參數，最後再以整體資料做訓練(refit)\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    # 印出最佳模型參數\n",
        "    if print_best_params == True:\n",
        "        print(search.best_params_)\n",
        "\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3 預先訓練多個模型並儲存**\n",
        "\n",
        "2023.04.06"
      ],
      "metadata": {
        "id": "LHpy0QVvfhRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwi3e9ofVGsv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# 訓練並儲存模型 (for grid search)\n",
        "def trainMonthlyRevenue(data: pd.DataFrame, y_test_start_yr: int, y_test_start_mon: int, y_test_end_yr: int, y_test_end_mon: int, modelName: str, save_path: str):\n",
        "    '''\n",
        "    當使用 grid search 需要花費大量時間預先訓練並儲存模型時適用。\n",
        "    \n",
        "    Parameters\n",
        "    ----------    \n",
        "    data: 資料集, \n",
        "    y_test_start_yr: 預測起始年, y_test_start_mon: 預測起始月, \n",
        "    y_test_end_yr: 預測終止年, y_test_end_mon: 預測終止月, \n",
        "    modelName: | 'rf' | 'xgb' |, \n",
        "    save_path: 模型欲儲存的位置\n",
        "    '''\n",
        "\n",
        "    test_y_m = month_range(y_test_start_yr, y_test_start_mon, y_test_end_yr, y_test_end_mon)  # 所有要預測的年月\n",
        "    back_most = 48    # 以前48個月的資料預測第t期\n",
        "    cv = 5\n",
        "\n",
        "    # 針對每個欲預測的年月\n",
        "    for i in test_y_m:\n",
        "        start = time.time()\n",
        "\n",
        "        y_test_yr = int(i.split(\"-\")[0])    # 預測的年\n",
        "        y_test_mon = int(i.split(\"-\")[1])   # 預測的月\n",
        "\n",
        "        #-----------------------取得訓練資料集-----------------------\n",
        "        # 原始資料\n",
        "        X_train, y_train, X_test, y_test = get_train_test(data, y_test_yr, y_test_mon, back_most, y_back=12)    # y_train 為 y_test 往前推 12 個月\n",
        "\n",
        "        # 平減資料（標準化資料）\n",
        "        mean_train, std_train, X_train_def = standardize_X(X_train)\n",
        "        y_train_def = standardize_y(mean_train, std_train, y_train)\n",
        "\n",
        "        # 拆解資料\n",
        "        trend_train, season_train, resid_train = decompose_data(X_train)\n",
        "        X_train_dec = pd.concat([trend_train, season_train, resid_train], axis=1)\n",
        "\n",
        "        # 拆解 + 平減資料（標準化資料）\n",
        "        mean_train_dec, std_train_dec, X_train_dec_def = standardize_X(X_train_dec)\n",
        "        y_train_dec_def = standardize_y(mean_train_dec, std_train_dec, y_train)\n",
        "\n",
        "        # 消除 seasonal effect\n",
        "        season_train.columns = X_train.columns.copy()\n",
        "        X_train_season = X_train - season_train\n",
        "\n",
        "        # 消除 seasonal effect + 平減資料（標準化資料）\n",
        "        mean_train_season, std_train_season, X_train_season_def = standardize_X(X_train_season)\n",
        "        y_train_season_def = standardize_y(mean_train_season, std_train_season, y_train)\n",
        "        \n",
        "        #-----------------------模型訓練-----------------------\n",
        "        print_best_params = False   # 設定是否要印出最佳模型參數\n",
        "        model = search_best_model(modelName, X_train, y_train, cv, print_best_params)\n",
        "        def_model = search_best_model(modelName, X_train_def, y_train_def, cv, print_best_params)\n",
        "        dec_model = search_best_model(modelName, X_train_dec, y_train, cv, print_best_params)\n",
        "        dec_def_model = search_best_model(modelName, X_train_dec_def, y_train_dec_def, cv, print_best_params)\n",
        "        season_model = search_best_model(modelName, X_train_season, y_train, cv, print_best_params)\n",
        "        season_def_model = search_best_model(modelName, X_train_season_def, y_train_season_def, cv, print_best_params)\n",
        "\n",
        "        #-----------------------儲存預測模型-----------------------\n",
        "        pickle.dump(model, open(f'{save_path}/{i}/model.pkl', 'wb'))\n",
        "        pickle.dump(def_model, open(f'{save_path}/{i}/def_model.pkl', 'wb'))\n",
        "        pickle.dump(dec_model, open(f'{save_path}/{i}/dec_model.pkl', 'wb'))\n",
        "        pickle.dump(dec_def_model, open(f'{save_path}/{i}/dec_def_model.pkl', 'wb'))\n",
        "        pickle.dump(season_model, open(f'{save_path}/{i}/season_model.pkl', 'wb'))\n",
        "        pickle.dump(season_def_model, open(f'{save_path}/{i}/season_def_model.pkl', 'wb'))\n",
        "        \n",
        "        print(f\"{i} model saved. Using time:\", \"%.3f\"%(time.time() - start), \" secs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Predicting and Evaluation**\n",
        "\n",
        "衡量指標：\n",
        "\n",
        "*   RMSE (Root Mean Square Error)\n",
        "\n",
        "$$RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(\\hat{y}_i - y_i)^2}$$\n",
        "\n",
        "<br>\n",
        "\n",
        "*   MAE (Mean Absolute Error)\n",
        "\n",
        "$$MAE = \\frac{1}{n}\\sum_{i=1}^n|\\hat{y}_i - y_i|$$\n",
        "\n",
        "<br>\n",
        "\n",
        "*   MAE% (MAE / mean of the sum of y_true)\n",
        "\n",
        "$$MAE\\% = \\frac{\\frac{1}{n}\\sum_{i=1}^n|\\hat{y}_i - y_i|}{\\frac{1}{n}\\sum_{i=1}^n y_i} = \\frac{\\sum_{i=1}^n|\\hat{y}_i - y_i|}{\\sum_{i=1}^n y_i}$$\n",
        "\n",
        "<br>\n",
        "\n",
        "*   MAPE (Mean Absolute Percentage Error)\n",
        "\n",
        "$$MAPE(\\%) = \\frac{1}{n}\\sum_{i=1}^n \\frac{|\\hat{y}_i - y_i|}{y_i}$$\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "0cyJa68O8cmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評估預測結果好壞\n",
        "def evaluatePerformance(y_true, y_pred, rmse: list, mae: list, mae_percent: list, mape: list):\n",
        "    '''\n",
        "    評估預測結果好壞。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true: 真實月營收, y_pred: 預測月營收, \n",
        "    rmse, mae, mae_percent, mape: 用來儲存各種衡量指標預測分數的 list\n",
        "    ''' \n",
        "    rmse.append(round(mean_squared_error(y_true, y_pred, squared=False), 0))\n",
        "    mae.append(round(mean_absolute_error(y_true, y_pred), 0))\n",
        "    mae_percent.append(round(mean_absolute_error(y_true, y_pred) / y_true.mean(), 4))\n",
        "    mape.append(round(mean_absolute_percentage_error(y_true, y_pred), 4))\n",
        "\n",
        "# 彙整不同衡量指標的預測分數 \n",
        "def savePerformace(scoresD, rmse: list, mae: list, mae_percent: list, mape: list, dataName: str):  \n",
        "    '''\n",
        "    彙整不同衡量指標的預測分數。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    scoresD: 彙整所有分數的 dataframe, \n",
        "    rmse, mae, mae_percent, mape: 各種衡量指標的預測分數, \n",
        "    dataName: | 'org' | 'dec' | 'season' |\n",
        "    ''' \n",
        "    scoresD[f'RMSE-{dataName}'] = rmse\n",
        "    scoresD[f'MAE-{dataName}'] = mae\n",
        "    scoresD[f'MAE%-{dataName}'] = mae_percent\n",
        "    scoresD[f'MAPE-{dataName}'] = mape"
      ],
      "metadata": {
        "id": "9Y-PLUYS9X0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm80lc3v-KDw"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# 預測並儲存結果\n",
        "def predictMonthlyRevenue(data: pd.DataFrame, y_test_start_yr: int, y_test_start_mon: int, y_test_end_yr: int, y_test_end_mon: int, modelName: str, search: bool = False, save_path: str = 'None'):\n",
        "    '''\n",
        "    預測月營收。\n",
        "    \n",
        "    Parameters\n",
        "    ----------    \n",
        "    data: 資料集, \n",
        "    y_test_start_yr: 預測起始年, y_test_start_mon: 預測起始月, \n",
        "    y_test_end_yr: 預測終止年, y_test_end_mon: 預測終止月, \n",
        "    modelName: | 'rf' | 'xgb' |, \n",
        "    search: grid search or not (default = False)\n",
        "    save_path: 模型儲存的位置，search = True 時才需要 (default = 'None')\n",
        "\n",
        "    Returns\n",
        "    ----------    \n",
        "    pred = \n",
        "    {\"org\": {\"org\": org_pred, \"dec\": dec_pred, \"season\": season_pred},\n",
        "     \"def\": {\"org\": def_pred, \"dec\": dec_def_pred, \"season\": season_def_pred}\n",
        "    },\n",
        "    \n",
        "    feature_importance = \n",
        "    {\"org\": {\"org\": feature_importance, \"dec\": feature_importance_dec, \"season\": feature_importance_season},\n",
        "     \"def\": {\"org\": feature_importance_def, \"dec\": feature_importance_dec_def, \"season\": feature_importance_season_def}\n",
        "    },\n",
        "\n",
        "    scores\n",
        "    '''\n",
        "\n",
        "    start = time.time()\n",
        "    test_y_m = month_range(y_test_start_yr, y_test_start_mon, y_test_end_yr, y_test_end_mon)  # 所有要預測的年月\n",
        "    back_most = 48    # 以前48個月的資料預測第t期\n",
        "    cv = 5\n",
        "\n",
        "    org_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄原始資料的預測值\n",
        "    feature_importance = pd.DataFrame()                         # 紀錄模型所計算出的 feature importance\n",
        "    def_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄平減資料的預測值\n",
        "    feature_importance_def = pd.DataFrame()                     # 紀錄模型所計算出的 feature importance\n",
        "\n",
        "    dec_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄拆解資料的預測值\n",
        "    feature_importance_dec = pd.DataFrame()                     # 紀錄模型所計算出的 feature importance\n",
        "    dec_def_pred = pd.DataFrame(index=data.index.tolist())      # 紀錄拆解資料+平減的預測值\n",
        "    feature_importance_dec_def = pd.DataFrame()                 # 紀錄模型所計算出的 feature importance\n",
        "\n",
        "    season_pred = pd.DataFrame(index=data.index.tolist())       # 紀錄消除 seasonal effect 資料的預測值\n",
        "    feature_importance_season = pd.DataFrame()                  # 紀錄模型所計算出的 feature importance\n",
        "    season_def_pred = pd.DataFrame(index=data.index.tolist())   # 紀錄消除 seasonal effect + 平減資料的預測值\n",
        "    feature_importance_season_def = pd.DataFrame()              # 紀錄模型所計算出的 feature importance\n",
        "\n",
        "    # 紀錄原始資料的預測分數\n",
        "    rmse_list = []\n",
        "    mae_list = []\n",
        "    mae_percent_list = []\n",
        "    mape_list = []\n",
        "\n",
        "    # 紀錄平減資料的預測分數\n",
        "    rmse_list_def = []\n",
        "    mae_list_def = []\n",
        "    mae_percent_list_def = []\n",
        "    mape_list_def = []\n",
        "\n",
        "    # 紀錄拆解資料的預測分數\n",
        "    rmse_list_dec = []\n",
        "    mae_list_dec = []\n",
        "    mae_percent_list_dec = []\n",
        "    mape_list_dec = []\n",
        "\n",
        "    # 紀錄拆解+平減資料的預測分數\n",
        "    rmse_list_dec_def = []\n",
        "    mae_list_dec_def = []\n",
        "    mae_percent_list_dec_def = []\n",
        "    mape_list_dec_def = []\n",
        "\n",
        "    # 紀錄消除 seasonal effect 資料的預測分數\n",
        "    rmse_list_season = []\n",
        "    mae_list_season = []\n",
        "    mae_percent_list_season = []\n",
        "    mape_list_season = []\n",
        "\n",
        "    # 紀錄消除 seasonal effect + 平減資料的預測分數\n",
        "    rmse_list_season_def = []\n",
        "    mae_list_season_def = []\n",
        "    mae_percent_list_season_def = []\n",
        "    mape_list_season_def = []\n",
        "\n",
        "    # 彙整所有預測分數\n",
        "    scores = pd.DataFrame(index=test_y_m)\n",
        "\n",
        "    # To fix fragmented problem (2023.04.08)\n",
        "    counter = 1\n",
        "\n",
        "    # 針對每個欲預測的年月\n",
        "    for i in test_y_m:\n",
        "\n",
        "        y_test_yr = int(i.split(\"-\")[0])    # 預測的年\n",
        "        y_test_mon = int(i.split(\"-\")[1])   # 預測的月\n",
        "\n",
        "        #-----------------------取得訓練和測試資料集-----------------------\n",
        "        # 原始資料\n",
        "        X_train, y_train, X_test, y_test = get_train_test(data, y_test_yr, y_test_mon, back_most, y_back=12)    # y_train 為 y_test 往前推 12 個月\n",
        "\n",
        "        # 平減資料（標準化資料）\n",
        "        mean_test, std_test, X_test_def = standardize_X(X_test)\n",
        "        mean_train, std_train, X_train_def = standardize_X(X_train)\n",
        "        y_train_def = standardize_y(mean_train, std_train, y_train)\n",
        "\n",
        "        # 拆解資料\n",
        "        trend_test, season_test, resid_test = decompose_data(X_test)\n",
        "        trend_train, season_train, resid_train = decompose_data(X_train)\n",
        "        X_test_dec = pd.concat([trend_test, season_test, resid_test], axis=1)\n",
        "        X_train_dec = pd.concat([trend_train, season_train, resid_train], axis=1)\n",
        "\n",
        "        # 拆解 + 平減資料（標準化資料）\n",
        "        mean_test_dec, std_test_dec, X_test_dec_def = standardize_X(X_test_dec)\n",
        "        mean_train_dec, std_train_dec, X_train_dec_def = standardize_X(X_train_dec)\n",
        "        y_train_dec_def = standardize_y(mean_train_dec, std_train_dec, y_train)\n",
        "\n",
        "        # 消除 seasonal effect\n",
        "        season_test.columns = X_test.columns.copy()     # Column name 相同才能相減  \n",
        "        season_train.columns = X_train.columns.copy()\n",
        "        X_test_season = X_test - season_test\n",
        "        X_train_season = X_train - season_train\n",
        "\n",
        "        # 消除 seasonal effect + 平減資料（標準化資料）\n",
        "        mean_test_season, std_test_season, X_test_season_def = standardize_X(X_test_season)\n",
        "        mean_train_season, std_train_season, X_train_season_def = standardize_X(X_train_season)\n",
        "        y_train_season_def = standardize_y(mean_train_season, std_train_season, y_train)\n",
        "        \n",
        "        #-----------------------模型訓練-----------------------\n",
        "        if search == False:\n",
        "            model = train_model(modelName, X_train, y_train)\n",
        "            def_model = train_model(modelName, X_train_def, y_train_def)\n",
        "            dec_model = train_model(modelName, X_train_dec, y_train)\n",
        "            dec_def_model = train_model(modelName, X_train_dec_def, y_train_dec_def)\n",
        "            season_model = train_model(modelName, X_train_season, y_train)\n",
        "            season_def_model = train_model(modelName, X_train_season_def, y_train_season_def)\n",
        "\n",
        "        else:   # 使用 Grid Search 代表模型已經事先訓練完成\n",
        "            model = pickle.load(open(f'{save_path}/{i}/model.pkl', 'rb'))\n",
        "            def_model = pickle.load(open(f'{save_path}/{i}/def_model.pkl', 'rb'))\n",
        "            dec_model = pickle.load(open(f'{save_path}/{i}/dec_model.pkl', 'rb'))\n",
        "            dec_def_model = pickle.load(open(f'{save_path}/{i}/dec_def_model.pkl', 'rb'))\n",
        "            season_model = pickle.load(open(f'{save_path}/{i}/season_model.pkl', 'rb'))\n",
        "            season_def_model = pickle.load(open(f'{save_path}/{i}/season_def_model.pkl', 'rb'))\n",
        "\n",
        "        #-----------------------儲存預測值-----------------------\n",
        "        org_pred[i] = np.round(model.predict(X_test), 0)\n",
        "        def_pred[i] = np.round(standardized_y_back(mean_test, std_test, def_model.predict(X_test_def)), 0)   # 將標準化的預測值轉換回原始值\n",
        "        dec_pred[i] = np.round(dec_model.predict(X_test_dec), 0)\n",
        "        dec_def_pred[i] = np.round(standardized_y_back(mean_test_dec, std_test_dec, dec_def_model.predict(X_test_dec_def)), 0)   # 將標準化的預測值轉換回原始值\n",
        "        season_pred[i] = np.round(season_model.predict(X_test_season), 0)\n",
        "        season_def_pred[i] = np.round(standardized_y_back(mean_test_season, std_test_season, season_def_model.predict(X_test_season_def)), 0)   # 將標準化的預測值轉換回原始值\n",
        "\n",
        "        # To fix fragmented problem (2023.04.08)\n",
        "        if counter == 100:\n",
        "            org_pred = org_pred.copy()\n",
        "            def_pred = def_pred.copy()\n",
        "            dec_pred = dec_pred.copy()\n",
        "            dec_def_pred = dec_def_pred.copy()\n",
        "            season_pred = season_pred.copy()\n",
        "            season_def_pred = season_def_pred.copy()\n",
        "\n",
        "        #-----------------------儲存變數重要性-----------------------\n",
        "        feature_importance[i] = np.round(model.feature_importances_, 4)\n",
        "        feature_importance_def[i] = np.round(def_model.feature_importances_, 4)\n",
        "        feature_importance_dec[i] = np.round(dec_model.feature_importances_, 4)\n",
        "        feature_importance_dec_def[i] = np.round(dec_def_model.feature_importances_, 4)\n",
        "        feature_importance_season[i] = np.round(season_model.feature_importances_, 4)\n",
        "        feature_importance_season_def[i] = np.round(season_def_model.feature_importances_, 4)\n",
        "\n",
        "        # To fix fragmented problem (2023.04.08)\n",
        "        if counter == 100:\n",
        "            feature_importance = feature_importance.copy()\n",
        "            feature_importance_def = feature_importance_def.copy()\n",
        "            feature_importance_dec = feature_importance_dec.copy()\n",
        "            feature_importance_dec_def = feature_importance_dec_def.copy()\n",
        "            feature_importance_season = feature_importance_season.copy()\n",
        "            feature_importance_season_def = feature_importance_season_def.copy()\n",
        "\n",
        "        #-----------------------儲存預測分數-----------------------\n",
        "        evaluatePerformance(y_test, org_pred[i], rmse_list, mae_list, mae_percent_list, mape_list)\n",
        "        evaluatePerformance(y_test, def_pred[i], rmse_list_def, mae_list_def, mae_percent_list_def, mape_list_def)\n",
        "        evaluatePerformance(y_test, dec_pred[i], rmse_list_dec, mae_list_dec, mae_percent_list_dec, mape_list_dec)\n",
        "        evaluatePerformance(y_test, dec_def_pred[i], rmse_list_dec_def, mae_list_dec_def, mae_percent_list_dec_def, mape_list_dec_def)\n",
        "        evaluatePerformance(y_test, season_pred[i], rmse_list_season, mae_list_season, mae_percent_list_season, mape_list_season)\n",
        "        evaluatePerformance(y_test, season_def_pred[i], rmse_list_season_def, mae_list_season_def, mae_percent_list_season_def, mape_list_season_def)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "    # Set feature names\n",
        "    feature_importance.index = model.feature_names_in_\n",
        "    feature_importance_def.index = def_model.feature_names_in_\n",
        "    feature_importance_dec.index = dec_model.feature_names_in_\n",
        "    feature_importance_dec_def.index = dec_def_model.feature_names_in_\n",
        "    feature_importance_season.index = season_model.feature_names_in_\n",
        "    feature_importance_season_def.index = season_def_model.feature_names_in_\n",
        "\n",
        "    # 彙整不同衡量指標的預測分數\n",
        "    savePerformace(scores, rmse_list, mae_list, mae_percent_list, mape_list, 'org')\n",
        "    savePerformace(scores, rmse_list_def, mae_list_def, mae_percent_list_def, mape_list_def, 'def')\n",
        "    savePerformace(scores, rmse_list_dec, mae_list_dec, mae_percent_list_dec, mape_list_dec, 'dec')\n",
        "    savePerformace(scores, rmse_list_dec_def, mae_list_dec_def, mae_percent_list_dec_def, mape_list_dec_def, 'dec_def')\n",
        "    savePerformace(scores, rmse_list_season, mae_list_season, mae_percent_list_season, mape_list_season, 'season')\n",
        "    savePerformace(scores, rmse_list_season_def, mae_list_season_def, mae_percent_list_season_def, mape_list_season_def, 'season_def')\n",
        "\n",
        "    # 將所有預測結果、變數重要性分別存在 dictionary 中 (2023.04.04 updated)\n",
        "    pred = {\"org\": {\"org\": org_pred,\n",
        "                    \"dec\": dec_pred,\n",
        "                    \"season\": season_pred\n",
        "                    },\n",
        "            \"def\": {\"org\": def_pred,\n",
        "                    \"dec\": dec_def_pred,\n",
        "                    \"season\": season_def_pred\n",
        "                    }\n",
        "            }\n",
        "\n",
        "    feature_importance = {\"org\": {\"org\": feature_importance,\n",
        "                                  \"dec\": feature_importance_dec,\n",
        "                                  \"season\": feature_importance_season\n",
        "                                  },\n",
        "                          \"def\": {\"org\": feature_importance_def,\n",
        "                                  \"dec\": feature_importance_dec_def,\n",
        "                                  \"season\": feature_importance_season_def\n",
        "                                  }\n",
        "                          }\n",
        "\n",
        "    print(\"Using time:\", \"%.3f\"%(time.time() - start), \" secs.\")\n",
        "\n",
        "    return pred, feature_importance, scores\n",
        "\n",
        "    # return org_pred, feature_importance, def_pred, feature_importance_def, dec_pred, feature_importance_dec, dec_def_pred, feature_importance_dec_def, season_pred, feature_importance_season, season_def_pred, feature_importance_season_def, scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Best and Worst Model**\n",
        "\n",
        "2023.04.05"
      ],
      "metadata": {
        "id": "tx48nPLSWN6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BestWorstModel():\n",
        "    '''\n",
        "    找出最好和最差模型。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    best_rf, worst_rf: dict\n",
        "        Random Forest 在各個衡量指標下最好和最差的模型。\n",
        "    best_xgb, worst_xgb: dict\n",
        "        XGB 在各個衡量指標下最好和最差的模型。\n",
        "    best_all, worst_all: dict\n",
        "        所有模型中，在各個衡量指標下最好和最差的模型。\n",
        "    ----------\n",
        "    best_worst_rf, best_worst_xgb: pd.DataFrame\n",
        "        各資料處理方式中，預測最好和最差的月份。\n",
        "    best_worst: pd.DataFrame\n",
        "        各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "\n",
        "    Methods\n",
        "    ----------\n",
        "    findBestWorstForAll(scoreType: str): \n",
        "        根據所選擇的衡量指標，找出各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, score_rf: pd.DataFrame, score_xgb: pd.DataFrame):\n",
        "        self.score_rf = score_rf\n",
        "        self.score_xgb = score_xgb\n",
        "        self.best_worst_rf, self.best_worst_xgb, self.best_worst = self.createBestWorstForAll()\n",
        "        self.best_rf, self.worst_rf = self.findBestWorstByModel('rf')\n",
        "        self.best_xgb, self.worst_xgb = self.findBestWorstByModel('xgb')\n",
        "        self.best_all, self.worst_all = self.findBestWorstByModel('all')\n",
        "\n",
        "    def createBestWorstForAll(self):\n",
        "        '''\n",
        "        各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "        '''\n",
        "        best_worst_rf = pd.DataFrame(columns = ['modelName', 'dataType', 'scoreType', 'min_month', 'min_score', 'max_month', 'max_score'])\n",
        "        best_worst_xgb = pd.DataFrame(columns = ['modelName', 'dataType', 'scoreType', 'min_month', 'min_score', 'max_month', 'max_score'])\n",
        "\n",
        "        # Random Forest\n",
        "        for colName, colData in self.score_rf.iteritems():\n",
        "            best_worst_rf.loc[len(best_worst_rf)] = ['Random Forest', colName.split(\"-\")[-1], colName.split(\"-\")[0], colData.idxmin(), colData.min(), colData.idxmax(), colData.max()]\n",
        "        # XGB\n",
        "        for colName, colData in self.score_xgb.iteritems():\n",
        "            best_worst_xgb.loc[len(best_worst_xgb)] = ['XGB', colName.split(\"-\")[-1], colName.split(\"-\")[0], colData.idxmin(), colData.min(), colData.idxmax(), colData.max()]\n",
        "        \n",
        "        # All\n",
        "        best_worst = pd.concat([best_worst_rf, best_worst_xgb])\n",
        "\n",
        "        # Sort by scoreType\n",
        "        best_worst_rf.sort_values(by=['scoreType'])\n",
        "        best_worst_xgb.sort_values(by=['scoreType'])\n",
        "\n",
        "        return best_worst_rf, best_worst_xgb, best_worst\n",
        "\n",
        "\n",
        "    def findBestWorstForAll(self, scoreType: str):\n",
        "        '''\n",
        "        根據所選擇的衡量指標，找出各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        scoreType: | 'RMSE' | 'MAPE' | 'MAE' | 'MAE%' |\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        best, worst\n",
        "        '''\n",
        "\n",
        "        scores = self.best_worst[self.best_worst['scoreType'] == scoreType]   # filter\n",
        "        best = scores.drop(['max_month', 'max_score'], axis=1)\n",
        "        worst = scores.drop(['min_month', 'min_score'], axis=1)\n",
        "\n",
        "        return best, worst\n",
        "\n",
        "\n",
        "    def findBestWorstByModel(self, modelName: str):\n",
        "        '''\n",
        "        根據所選擇的模型，找出不同衡量指標下預測最好和最差的月份。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        modelName: | 'rf' | 'xgb' | 'all' |\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        best_dict: {\"RMSE\", \"MAPE\", \"MAE\", \"MAE%\"}\n",
        "        worst_dict: {\"RMSE\", \"MAPE\", \"MAE\", \"MAE%\"}\n",
        "        '''\n",
        "\n",
        "        if modelName == 'rf':\n",
        "            scoreD = self.best_worst_rf.copy()\n",
        "        elif modelName == 'xgb':\n",
        "            scoreD = self.best_worst_xgb.copy()\n",
        "        elif modelName == 'all':\n",
        "            scoreD = self.best_worst.copy()\n",
        "\n",
        "        best_dict = {}\n",
        "        worst_dict = {}\n",
        "\n",
        "        scoreTypes = ['RMSE', 'MAPE', 'MAE', 'MAE%']\n",
        "        for s in scoreTypes:\n",
        "            scores = scoreD[scoreD['scoreType'] == s]   # filter\n",
        "            best = scores[scores.min_score == scores.min_score.min()]\n",
        "            best = best.drop(['max_month', 'max_score'], axis=1)\n",
        "            best_dict[s] = best\n",
        "            worst = scores[scores.max_score == scores.max_score.max()]\n",
        "            worst = worst.drop(['min_month', 'min_score'], axis=1)\n",
        "            worst_dict[s] = worst\n",
        "\n",
        "        return best_dict, worst_dict\n",
        "          \n",
        "    # def printBestWorst(self, scoreD, scoreType: str):\n",
        "    #     print('Best Model')\n",
        "    #     print(f\"Model Name: {modelName}, Data Type: {dataType}, Month: {min_month}, Score: {min_score} ({scoreType})\")\n",
        "    #     print('Worst Model')\n",
        "    #     print(f\"Model Name: {modelName}, Data Type: {dataType}, Month: {max_month}, Score: {max_score} ({scoreType})\")\n"
      ],
      "metadata": {
        "id": "9rl8dPOYPHwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}