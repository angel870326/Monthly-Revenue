{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sP1USHnpKYuB",
        "_HaoKhsavIc0"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOwxsaNwjWfVeuF7ySU2rxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angel870326/Monthly-Revenue-Forecasting/blob/main/Function/MonRevForecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3UyvF37PpZp"
      },
      "source": [
        "> 2023.04.14 Ssu-Yun Wang<br/>\n",
        "[Github @angel870326](https://github.com/angel870326)\n",
        "\n",
        "# **Monthly Revenue Forecasting with Random Forest Regressor, XGB Regressor, RNN & LSTM - Model**\n",
        "\n",
        "### Contents\n",
        "\n",
        "##### 4. Functions\n",
        "##### 5. Model Training\n",
        "##### 6. Predicting and Evaluation\n",
        "##### 9. Best and Worst Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.seasonal import STL"
      ],
      "metadata": {
        "id": "QGu9WzMGctsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP1USHnpKYuB"
      },
      "source": [
        "## **4. Functions**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1 推算月份並取得資料**"
      ],
      "metadata": {
        "id": "gR1pXchojlqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QakiMtVvlDQ"
      },
      "outputs": [],
      "source": [
        "# 往前推算月份\n",
        "def back_month(yr: int, mon: int, back: int):\n",
        "    '''\n",
        "    往前推算月份。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    yr: 第t期的年, mon: 第t期的月, back: 往前推算幾個月\n",
        "    '''\n",
        "\n",
        "    # 若當下月份(mon)減除往前期數(b)大於0，即還在同一年內\n",
        "    if mon - back > 0:                         \n",
        "        return str(yr) + '-' + str(mon - back)      # 直接回傳當下年份(yr)，以及當下月份(mon)減除往前期數(back)，所組成的字串\n",
        "    # 不屬於同一年\n",
        "    else:                               \n",
        "        return back_month(yr - 1, mon, back - 12)   # 手動調減一年，並將往前期數(back)減少12個月"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpomeaaOwTe1"
      },
      "outputs": [],
      "source": [
        "# 取得 t-back_most ~ t-1 期的 X 資料\n",
        "def X_months(data: pd.DataFrame, y_yr: int, y_mon: int, back_most: int):\n",
        "    '''\n",
        "    取得 t-back_most ~ t-1 期的 X 資料。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集; y_yr: 第t期的年, y_mon: 第t期的月, back_most: X的最早月份是第t期的往前多少月份\n",
        "    '''\n",
        "\n",
        "    months = []\n",
        "    for b in range(back_most, 0, -1):               # 從 back_most 到 1\n",
        "        months.append(back_month(y_yr, y_mon, b))   # 根據每個往前月份數(b)推算對應年月，儲存進 months 之中\n",
        "    \n",
        "    # 回傳 data 中的這些月份\n",
        "    return data[months]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvre6fxJqIr-"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# 取得起始年月到終止年月的每個年月\n",
        "def month_range(y_start_yr: int, y_start_mon: int, y_end_yr: int, y_end_mon: int):\n",
        "    '''\n",
        "    取得起始年月到終止年月的每個年月。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_start_yr: 起始年, y_start_mon: 起始月, y_end_yr: 終止年, y_end_mon: 終止月\n",
        "    '''\n",
        "\n",
        "    start_ym = str(y_start_yr) + '-' + str(y_start_mon)\n",
        "    \n",
        "    # pd.date_range 中的 end 為終止月的下一個月，因此須將終止年月加 1 個月\n",
        "    if y_end_mon < 12:\n",
        "        end_ym = str(y_end_yr) + '-' + str(y_end_mon + 1)   # 終止月為1-11月時，直接在月份+1\n",
        "    else: \n",
        "        end_ym = str(y_end_yr + 1) + '-' + '1'              # 終止月為12月時，end 設為下一年的1月\n",
        "    \n",
        "    # 生成從起始年月到終止年月的每個年月\n",
        "    month_list = pd.date_range(start=start_ym, end=end_ym, freq='M').to_period('M').strftime('%Y-%m').to_numpy()\n",
        "\n",
        "    return month_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2 平減資料**"
      ],
      "metadata": {
        "id": "JgTDFOwIjt6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.2.1 水平方向（對各公司分別做平減）**"
      ],
      "metadata": {
        "id": "WKImU7twj1lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 對 X 做標準化（和 sklearn 的 StandardScaler、MinMaxScaler 公式相同）\n",
        "def standardize_X(data: pd.DataFrame, scaler: str = 'std'):\n",
        "    '''\n",
        "    對 X 做標準化。\n",
        "\n",
        "    Parameters \n",
        "    ----------\n",
        "    data: X,\n",
        "    scaler: | 'std' | 'minmax'\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    mean, min, max, std, std_data\n",
        "    '''\n",
        "\n",
        "    mean = data.mean(axis=1)\n",
        "    min = data.min(axis=1)\n",
        "    max = data.max(axis=1)\n",
        "\n",
        "    if scaler == 'std':\n",
        "        std = data.std(axis=1)\n",
        "        std_data = data.apply(lambda row: (row - mean[row.name]) / std[row.name], axis=1)\n",
        "    elif scaler == 'minmax':    # 2023.05.05\n",
        "        std = data.apply(lambda row: (row - min[row.name]) / (max[row.name] - min[row.name]), axis=1)\n",
        "        std_data = std * (1 - 0) + 0\n",
        "\n",
        "    return mean, min, max, std, std_data"
      ],
      "metadata": {
        "id": "UAxT8ToSzMnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 以 X 的平均數（或最小值、最大值）和標準差對 y 做標準化\n",
        "def standardize_y(mean: pd.Series, min: pd.Series, max: pd.Series, std: pd.DataFrame, data: pd.Series, scaler: str = 'std'):\n",
        "    '''\n",
        "    以 X 的平均數和標準差對 y 做標準化。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mean: X 的平均數, min: X 的最小值, max: X 的最大值, std: X 的標準差, data: y,\n",
        "    scaler: | 'std' | 'minmax'\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    std_data\n",
        "    '''\n",
        "\n",
        "    std_data = []\n",
        "    for i in range(len(data)):\n",
        "        if scaler == 'std':\n",
        "            std_data.append((data[i] - mean[i]) / std[i])\n",
        "        elif scaler == 'minmax':    # 2023.05.05\n",
        "            std_data.append(((data[i] - min[i]) / (max[i] - min[i])) * (1 - 0) + 0)\n",
        "\n",
        "    return std_data"
      ],
      "metadata": {
        "id": "ciISpfzlzQKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 將標準化的 y 轉回正常值\n",
        "def standardized_y_back(mean: pd.Series, min: pd.Series, max: pd.Series, std: pd.DataFrame, std_data: np.array, scaler: str = 'std'):\n",
        "    '''\n",
        "    將標準化的 y 轉回原始值。\n",
        "\n",
        "    Parameters \n",
        "    ----------\n",
        "    mean: X 的平均數, min: X 的最小值, max: X 的最大值, std: X 的標準差, std_data: 標準化的 y\n",
        "    scaler: | 'std' | 'minmax'\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    data\n",
        "    '''\n",
        "\n",
        "    data = []\n",
        "    for i in range(len(std_data)):\n",
        "        if scaler == 'std':\n",
        "            data.append(std_data[i] * std[i] + mean[i])\n",
        "        elif scaler == 'minmax':    # 2023.05.05\n",
        "            data.append((std_data[i] - 0) / (1 - 0) * (max[i] - min[i]) + min[i])\n",
        "    return data"
      ],
      "metadata": {
        "id": "Zya4tFamzSax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.2.2 垂直方向（對 feature 做平減）**\n",
        "\n",
        "2023.05.05"
      ],
      "metadata": {
        "id": "CS4yTOLZj841"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "Un_jtVG7kbVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 對 X 做標準化\n",
        "def scaler_X(data: pd.DataFrame, scaler: str = 'minmax'):\n",
        "    '''\n",
        "    對 X 做標準化。\n",
        "\n",
        "    Parameters \n",
        "    ----------\n",
        "    data: X,\n",
        "    scaler: | 'std' | 'minmax'\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    scaled_data\n",
        "    '''\n",
        "\n",
        "    if scaler == 'std':\n",
        "        scaled_data = pd.DataFrame(StandardScaler().fit_transform(data), index = data.index, columns = data.columns)\n",
        "    elif scaler == 'minmax':\n",
        "        scaled_data = pd.DataFrame(MinMaxScaler().fit_transform(data), index = data.index, columns = data.columns)\n",
        "\n",
        "    return scaled_data"
      ],
      "metadata": {
        "id": "f-w3ZEEgjOmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3 拆解資料**"
      ],
      "metadata": {
        "id": "ukWSKy9zlMpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwXXzhQZFoRA"
      },
      "outputs": [],
      "source": [
        "# 將資料拆解為 trend, seasonal, residual\n",
        "def decompose_data(data: pd.DataFrame):\n",
        "    '''\n",
        "    將資料拆解為 trend, seasonal, residual，並回傳三個資料集。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    trend, seasonal, residual\n",
        "    '''\n",
        "    trend = pd.DataFrame(index=data.index, columns=[c + '_trend' for c in data.columns], dtype=float)       # 在日期變數後面加上影響因素名稱\n",
        "    seasonal = pd.DataFrame(index=data.index, columns=[c + '_season' for c in data.columns], dtype=float)\n",
        "    residual = pd.DataFrame(index=data.index, columns=[c + '_resid' for c in data.columns], dtype=float)\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        decomposed_row = STL(row.to_numpy(), period=12, seasonal=13).fit()\n",
        "        trend.loc[index] = np.round(decomposed_row.trend, 4)\n",
        "        seasonal.loc[index] = np.round(decomposed_row.seasonal, 4)\n",
        "        residual.loc[index] = np.round(decomposed_row.resid, 4)\n",
        "\n",
        "    # decomposed_data = pd.concat([trend, seasonal, residual], axis=1)\n",
        "\n",
        "    return trend, seasonal, residual"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.4 取得訓練和測試資料集**"
      ],
      "metadata": {
        "id": "OahOpHQalRwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wvWltuLNX86"
      },
      "outputs": [],
      "source": [
        "# 取得訓練和測試資料集\n",
        "def get_train_test(data: pd.DataFrame, y_test_yr: int, y_test_mon: int, back_most: int, y_back: int):\n",
        "    '''\n",
        "    取得訓練和測試資料集。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集, y_test_yr: 要預測的年, y_test_mon: 要預測的月, \n",
        "    back_most: X的最早月份是第t期的往前多少月份, \n",
        "    y_back: 訓練資料集的y要比測試資料集的y往前多少月份\n",
        "\n",
        "    Returns \n",
        "    ----------\n",
        "    X_train, y_train, X_test, y_test\n",
        "    '''\n",
        "\n",
        "    # 測試資料\n",
        "    y_test = data[f'{y_test_yr}-{y_test_mon}']\n",
        "    X_test = X_months(data, y_test_yr, y_test_mon, back_most)\n",
        "    # 訓練資料\n",
        "    y_train_ym = back_month(y_test_yr, y_test_mon, y_back)\n",
        "    y_train = data[y_train_ym]\n",
        "    X_train = X_months(data, int(y_train_ym.split(\"-\")[0]), int(y_train_ym.split(\"-\")[1]), back_most)\n",
        "    # 更改X的變數名稱為 t-? 期\n",
        "    X_test.columns = [\"t-\"+str(t) for t in range(back_most, 0, -1)]                                     \n",
        "    X_train.columns = [\"t-\"+str(t) for t in range(back_most, 0, -1)]     \n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 取得訓練和測試資料集（以年為單位）\n",
        "# def get_train_test_year(data: pd.DataFrame, y_test_yr: int, back_most: int):\n",
        "#     '''\n",
        "#     取得訓練和測試資料集（以年為單位）。\n",
        "\n",
        "#     Parameters\n",
        "#     ----------\n",
        "#     data: 資料集, y_test_yr: 要預測的年,\n",
        "#     back_most: X的最早月份是第t期的往前多少月份, \n",
        "\n",
        "#     Returns \n",
        "#     ----------\n",
        "#     X_train, y_train, X_test, y_test\n",
        "#     '''\n",
        "\n",
        "#     # 測試資料\n",
        "#     y_test_ym = month_range(y_test_yr, 1, y_test_yr, 12)\n",
        "#     y_test = data[y_test_ym]\n",
        "#     X_test = X_months(data, y_test_yr, 1, back_most)\n",
        "#     # 訓練資料\n",
        "#     y_train_ym = month_range(y_test_yr-1, 1, y_test_yr-1, 12)\n",
        "#     y_train = data[y_train_ym]\n",
        "#     X_train = X_months(data, y_test_yr-1, 1, back_most)\n",
        "#     # 更改X的變數名稱為 t-? 期\n",
        "#     X_test.columns = [\"t-\"+str(t) for t in range(back_most, 0, -1)]                                     \n",
        "#     X_train.columns = [\"t-\"+str(t) for t in range(back_most, 0, -1)]     \n",
        "\n",
        "#     return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "7me9o--PZIH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.5 Feature Encoding for Industry Data**\n",
        "\n",
        "2023.05.06"
      ],
      "metadata": {
        "id": "_HaoKhsavIc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPYixjzW4iIR",
        "outputId": "acd272ce-191d-492a-bdc6-135b2bd6610e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders import TargetEncoder"
      ],
      "metadata": {
        "id": "nyvtMxHb3Y_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_encoding(data: pd.DataFrame, y: str):\n",
        "    '''\n",
        "    Target encoding for categorial data。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集,\n",
        "    y: 目標值名稱\n",
        "\n",
        "    Returns \n",
        "    ----------\n",
        "    Encoded data\n",
        "    '''\n",
        "\n",
        "    encoder = TargetEncoder(cols=['industry'], smoothing=1.0)\n",
        "    data['industry'] = encoder.fit_transform(data['industry'], data[y])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "I3i48VNTvUk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beta_target_encoding(data: pd.DataFrame, y: pd.Series):\n",
        "    '''\n",
        "    Beta target encoding for categorial data。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: 資料集,\n",
        "    y: 目標值名稱\n",
        "\n",
        "    Returns \n",
        "    ----------\n",
        "    Encoded data\n",
        "    '''\n",
        "\n",
        "    # Mean target value for each category\n",
        "    means = data.groupby('industry')[y].mean()\n",
        "\n",
        "    # Size of each category\n",
        "    sizes = data.groupby('industry').size()\n",
        "\n",
        "    # Beta parameter\n",
        "    beta = 0.5\n",
        "\n",
        "    # Calculate the encoding\n",
        "    encodings = (means * sizes + data[y].mean() * beta) / (sizes + beta)\n",
        "\n",
        "    # Replace the categories with their encodings\n",
        "    data['industry'] = data['industry'].map(encodings)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "fF_qsAhy2t6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_industry(data: pd.DataFrame, industry_data: pd.Series, encoded: bool = False):\n",
        "    '''\n",
        "    加入產業變數。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: X 資料集,\n",
        "    industry_data: 產業變數,\n",
        "    encoded: default = False\n",
        "\n",
        "    Returns \n",
        "    ----------\n",
        "    final_data\n",
        "    '''\n",
        "\n",
        "    final_data = pd.concat([data, industry_data], axis=1)\n",
        "\n",
        "    if encoded == True:\n",
        "        if 't-1' in final_data .columns:\n",
        "            y = 't-1'\n",
        "        else:\n",
        "            y = 't-1_trend'\n",
        "\n",
        "        # final_data = target_encoding(final_data, y)\n",
        "        final_data = beta_target_encoding(final_data, y)\n",
        "\n",
        "    return final_data"
      ],
      "metadata": {
        "id": "9Ta0Yj5-7rA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDwS7pKujcJY"
      },
      "source": [
        "## **5. Model Training**\n",
        "\n",
        "* RandomForestRegressor\n",
        "* XGBRegressor\n",
        "* SimpleRNN\n",
        "* LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK_7x3L6i-p2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# Evaluation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1 Random Forest & XGB**\n",
        "\n",
        "[RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) & [XGBRegressor](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor)"
      ],
      "metadata": {
        "id": "J5GfiPLxIg2T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTE_36HPI1Tn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.1.1 Parameter Grid for Grid Search**"
      ],
      "metadata": {
        "id": "TfZ95n_4fEDL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuanmZ74SASz"
      },
      "outputs": [],
      "source": [
        "# Parameter grid for grid search\n",
        "rf_params = {\"n_estimators\": [100], \n",
        "             \"random_state\": [0], \n",
        "             \"n_jobs\": [-1]\n",
        "             }\n",
        "\n",
        "xgb_params = {\"n_estimators\": [100, 250, 500], \n",
        "              \"objective\": ['reg:squarederror'],\n",
        "              \"learning_rate\":[0.1, 0.2],  # usually range from 0.01 to 0.2\n",
        "              # \"random_state\": [0],\n",
        "              \"n_jobs\": [-1]\n",
        "             }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.1.2 訓練單一模型（Random Forest or XGB）**"
      ],
      "metadata": {
        "id": "n2dDeSnCfRuf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_M6SlG0CjrE"
      },
      "outputs": [],
      "source": [
        "# 訓練模型\n",
        "def train_model(modelName, X_train, y_train):\n",
        "    '''\n",
        "    以預先設定好的參數訓練模型。\n",
        "\n",
        "    Parameters\n",
        "    ---------- \n",
        "    modelName: | 'rf' | 'xgb' |, X_train: 訓練資料的X, y_train: 訓練資料的y\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    model\n",
        "    '''\n",
        "    if modelName == 'rf':\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=0, criterion='squared_error', n_jobs=-1) \n",
        "        model.fit(X_train, y_train)\n",
        "    elif modelName == 'xgb':\n",
        "        model = XGBRegressor(n_estimators=500, learning_rate=0.01, objective='reg:squarederror', n_jobs=-1, eval_metric=mean_squared_error, booster='gblinear')\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Grid Search 找出最佳模型參數 (Hyperparameters tuned by k-fold cross validation)\n",
        "def search_best_model(modelName, X_train, y_train, cv: int, print_best_params: bool = False):\n",
        "    '''\n",
        "    做 Cross Validation 找出最佳模型參數。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    modelName: | 'rf' | 'xgb' |, X_train: 訓練資料的X, y_train: 訓練資料的y, \n",
        "    cv: K-Fold, \n",
        "    print_best_params: 是否要印出最佳模型參數（預設為否）\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    best_model\n",
        "    '''\n",
        "    if modelName == 'rf':\n",
        "        base_estimator = RandomForestRegressor()\n",
        "        params = rf_params.copy()\n",
        "    elif modelName == 'xgb':\n",
        "        base_estimator = XGBRegressor()\n",
        "        params = xgb_params.copy()\n",
        "    \n",
        "    # RMSE: 'neg_root_mean_squared_error'\n",
        "    # MSE: 'neg_mean_squared_error'\n",
        "    # MAE: 'neg_mean_absolute_error'\n",
        "\n",
        "    search = GridSearchCV(base_estimator, params, scoring='neg_mean_squared_error', cv=cv, refit=True, n_jobs=-1)\n",
        "    search.fit(X_train, y_train)          # 對訓練資料做 cross validation，找出最佳模型參數，最後再以整體資料做訓練(refit)\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    # 印出最佳模型參數\n",
        "    if print_best_params == True:\n",
        "        print(search.best_params_)\n",
        "\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.1.3 預先訓練多個模型並儲存**\n",
        "\n",
        "2023.04.06"
      ],
      "metadata": {
        "id": "LHpy0QVvfhRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwi3e9ofVGsv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# 訓練並儲存模型\n",
        "def trainMonthlyRevenue(data: pd.DataFrame, y_test_start_yr: int, y_test_start_mon: int, y_test_end_yr: int, y_test_end_mon: int, modelName: str, save_path: str, search: bool = False, industry_data = None, encoded: bool = False):\n",
        "    '''\n",
        "    預先訓練並儲存模型。\n",
        "    \n",
        "    Parameters\n",
        "    ----------    \n",
        "    data: 資料集, \n",
        "    y_test_start_yr: 預測起始年, y_test_start_mon: 預測起始月, \n",
        "    y_test_end_yr: 預測終止年, y_test_end_mon: 預測終止月, \n",
        "    modelName: | 'rf' | 'xgb' |, \n",
        "    save_path: 模型欲儲存的位置,\n",
        "    search: grid search or not (default = False),\n",
        "    industry_data: 產業變數，default = None (不加入產業變數),\n",
        "    encoded: 產業變數是否要使用 target encoding (default = False)\n",
        "    '''\n",
        "\n",
        "    test_y_m = month_range(y_test_start_yr, y_test_start_mon, y_test_end_yr, y_test_end_mon)  # 所有要預測的年月\n",
        "    back_most = 48    # 以前48個月的資料預測第t期\n",
        "    cv = 5\n",
        "\n",
        "    # 針對每個欲預測的年月\n",
        "    for i in test_y_m:\n",
        "        start = time.time()\n",
        "\n",
        "        y_test_yr = int(i.split(\"-\")[0])    # 預測的年\n",
        "        y_test_mon = int(i.split(\"-\")[1])   # 預測的月\n",
        "\n",
        "        #-----------------------取得訓練資料集-----------------------\n",
        "        # 原始資料\n",
        "        X_train, y_train, X_test, y_test = get_train_test(data, y_test_yr, y_test_mon, back_most, y_back=12)    # y_train 為 y_test 往前推 12 個月\n",
        "\n",
        "        # 拆解資料\n",
        "        trend_train, season_train, resid_train = decompose_data(X_train)\n",
        "        X_train_dec = pd.concat([trend_train, season_train, resid_train], axis=1)\n",
        "\n",
        "        # 消除 seasonal effect\n",
        "        season_train.columns = X_train.columns.copy()\n",
        "        X_train_season = X_train - season_train\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        if industry_data is not None:\n",
        "            X_train = add_industry(X_train, industry_data, encoded)\n",
        "            X_train_dec = add_industry(X_train_dec, industry_data, encoded)\n",
        "            X_train_season = add_industry(X_train_season, industry_data, encoded)\n",
        "\n",
        "        #-----------------------取得平減（標準化）訓練資料集-----------------------\n",
        "        # 平減資料（標準化資料）\n",
        "        mean_train, min_train, max_train, std_train, X_train_def = standardize_X(X_train)\n",
        "        y_train_def = standardize_y(mean_train, min_train, max_train, std_train, y_train)\n",
        "\n",
        "        # 拆解 + 平減資料（標準化資料）\n",
        "        mean_train_dec, min_train_dec, max_train_dec, std_train_dec, X_train_dec_def = standardize_X(X_train_dec)\n",
        "        y_train_dec_def = standardize_y(mean_train_dec, min_train_dec, max_train_dec, std_train_dec, y_train)\n",
        "\n",
        "        # 消除 seasonal effect + 平減資料（標準化資料）\n",
        "        mean_train_season, min_train_season, max_train_season, std_train_season, X_train_season_def = standardize_X(X_train_season)\n",
        "        y_train_season_def = standardize_y(mean_train_season, min_train_season, max_train_season, std_train_season, y_train)\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        # if industry_data is not None:\n",
        "        #     X_train = add_industry(X_train, industry_data, encoded)\n",
        "        #     X_train_dec = add_industry(X_train_dec, industry_data, encoded)\n",
        "        #     X_train_season = add_industry(X_train_season, industry_data, encoded)\n",
        "        #     X_train_def = add_industry(X_train_def, industry_data, encoded)\n",
        "        #     X_train_dec_def = add_industry(X_train_dec_def, industry_data, encoded)\n",
        "        #     X_train_season_def = add_industry(X_train_season_def, industry_data, encoded)\n",
        "\n",
        "        #-----------------------模型訓練-----------------------\n",
        "        if search == True:\n",
        "            print_best_params = False   # 設定是否要印出最佳模型參數\n",
        "            model = search_best_model(modelName, X_train, y_train, cv, print_best_params)\n",
        "            def_model = search_best_model(modelName, X_train_def, y_train_def, cv, print_best_params)\n",
        "            dec_model = search_best_model(modelName, X_train_dec, y_train, cv, print_best_params)\n",
        "            dec_def_model = search_best_model(modelName, X_train_dec_def, y_train_dec_def, cv, print_best_params)\n",
        "            season_model = search_best_model(modelName, X_train_season, y_train, cv, print_best_params)\n",
        "            season_def_model = search_best_model(modelName, X_train_season_def, y_train_season_def, cv, print_best_params)\n",
        "\n",
        "        else:\n",
        "            model = train_model(modelName, X_train, y_train)\n",
        "            def_model = train_model(modelName, X_train_def, y_train_def)\n",
        "            dec_model = train_model(modelName, X_train_dec, y_train)\n",
        "            dec_def_model = train_model(modelName, X_train_dec_def, y_train_dec_def)\n",
        "            season_model = train_model(modelName, X_train_season, y_train)\n",
        "            season_def_model = train_model(modelName, X_train_season_def, y_train_season_def)\n",
        "       \n",
        "        #-----------------------儲存預測模型-----------------------\n",
        "        pickle.dump(model, open(f'{save_path}/{i}/model.pkl', 'wb'))\n",
        "        pickle.dump(def_model, open(f'{save_path}/{i}/def_model.pkl', 'wb'))\n",
        "        pickle.dump(dec_model, open(f'{save_path}/{i}/dec_model.pkl', 'wb'))\n",
        "        pickle.dump(dec_def_model, open(f'{save_path}/{i}/dec_def_model.pkl', 'wb'))\n",
        "        pickle.dump(season_model, open(f'{save_path}/{i}/season_model.pkl', 'wb'))\n",
        "        pickle.dump(season_def_model, open(f'{save_path}/{i}/season_def_model.pkl', 'wb'))\n",
        "        \n",
        "        print(f\"{i} model saved. Using time:\", \"%.3f\"%(time.time() - start), \" secs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.2 RNN & LSTM**\n",
        "\n",
        "2023.04.13\n",
        "\n",
        "[SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) & [LSTM](https://keras.io/api/layers/recurrent_layers/lstm/)"
      ],
      "metadata": {
        "id": "W3lB_TMv6JSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.2.1 Reshaping X**"
      ],
      "metadata": {
        "id": "vTTwFxSGJQ0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reshapeInputNN(X: pd.DataFrame):\n",
        "    '''\n",
        "    Reshape input to be [samples, time steps, features]\n",
        "    '''\n",
        "    reshapedX = np.reshape(X.to_numpy(), (X.shape[0], 1, X.shape[1]))\n",
        "    return  reshapedX"
      ],
      "metadata": {
        "id": "A8McMqZTCjSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshapeInputNNforAll(X, X_def, X_dec, X_dec_def, X_season, X_season_def):\n",
        "    '''\n",
        "    Reshape all the inputs to be [samples, time steps, features]\n",
        "\n",
        "    Parameters\n",
        "    ---------- \n",
        "    X, X_def, X_dec, X_dec_def, X_season, X_season_def\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    Reshaped training or testing X\n",
        "    '''\n",
        " \n",
        "    X = reshapeInputNN(X)                         # 原始資料\n",
        "    X_def = reshapeInputNN(X_def)                 # 平減資料（標準化資料）\n",
        "    X_dec = reshapeInputNN(X_dec)                 # 拆解資料\n",
        "    X_dec_def = reshapeInputNN(X_dec_def)         # 拆解 + 平減資料（標準化資料）\n",
        "    X_season = reshapeInputNN(X_season)           # 消除 seasonal effect\n",
        "    X_season_def = reshapeInputNN(X_season_def)   # 消除 seasonal effect + 平減資料（標準化資料）\n",
        "\n",
        "    return X, X_def, X_dec, X_dec_def, X_season, X_season_def"
      ],
      "metadata": {
        "id": "JDUPzxI9-r_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.2.2 訓練單一模型（SimpleRNN or LSTM）**\n",
        "2023.04.18 updated for deflating data except for decomposed data<br>\n",
        "2023.05.07 architectures modified<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "-381t-fHJXcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import pickle"
      ],
      "metadata": {
        "id": "pbCShel39kJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "epochs_def = 5    # 2023.04.18\n",
        "# epochs_dec_def = 10    # 2023.05.11\n",
        "batch_size = 1\n",
        "verbose = 0"
      ],
      "metadata": {
        "id": "yrjufJE0HPoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModelNN(modelName, X_train, y_train, save_path: str, date: str, name: str):\n",
        "    '''\n",
        "    訓練並儲存模型。\n",
        "\n",
        "    Parameters\n",
        "    ---------- \n",
        "    modelName: | 'rnn' | 'lstm' |, \n",
        "    X_train: 訓練資料的X, y_train: 訓練資料的y,\n",
        "    save_path: 模型欲儲存的位置,\n",
        "    date: 測試年月, \n",
        "    name: 模型名稱 (model, def_model, dec_model, dec_def_model, season_model, season_def_model)\n",
        "    '''\n",
        "\n",
        "    y_train = np.array(y_train)   # Convert list to np.array\n",
        "\n",
        "    # val_data = None\n",
        "    val_data = (X_train, y_train)   # 2023.04.18 Add training data as validation data\n",
        "\n",
        "\n",
        "    #----------------------- Compile model -----------------------\n",
        "    model = Sequential() \n",
        "\n",
        "    if modelName == 'rnn':\n",
        "        # if ('def' in name) and ('dec' not in name):\n",
        "        if 'def' in name:\n",
        "            model.add(SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation=\"relu\", return_sequences=True))\n",
        "            model.add(Dropout(0.2))           \n",
        "            model.add(SimpleRNN(64))\n",
        "            model.add(Dropout(0.2))\n",
        "            model.add(Dense(32, activation='relu'))\n",
        "            model.add(Dense(1))\n",
        "        \n",
        "        else:\n",
        "            model.add(SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation=\"relu\"))\n",
        "            model.add(Dense(32))\n",
        "            model.add(Dense(1))\n",
        "\n",
        "    elif modelName == 'lstm':\n",
        "        # if ('def' in name) and ('dec' not in name):\n",
        "        if 'def' in name:\n",
        "            model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation=\"relu\", return_sequences=True))\n",
        "            model.add(Dropout(0.2))\n",
        "            model.add(LSTM(32))\n",
        "            model.add(Dropout(0.2))\n",
        "            model.add(Dense(1))\n",
        "\n",
        "        else:\n",
        "            model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation=\"relu\", return_sequences=True))\n",
        "            model.add(LSTM(64, activation=\"relu\"))\n",
        "            model.add(Dense(1))\n",
        "            \n",
        "    \n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
        "    # model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mse'])    # 2023.04.16\n",
        "\n",
        "\n",
        "    #----------------------- Save the model with the lowest val_loss (mse) -----------------------\n",
        "    if ('def' in name) and ('dec' not in name):   # 2023.04.18\n",
        "            checkpoint = ModelCheckpoint(filepath=f'{save_path}/{date}/{name}.h5', monitor='val_loss', verbose=verbose, save_best_only=True, mode='min')\n",
        "            history = model.fit(X_train, y_train, epochs=epochs_def, batch_size=batch_size, verbose=verbose, callbacks=[checkpoint], shuffle=False, validation_data=val_data)\n",
        "        # if 'dec' in name:   # 2023.05.11\n",
        "        #     checkpoint = ModelCheckpoint(filepath=f'{save_path}/{date}/{name}.h5', monitor='val_loss', verbose=verbose, save_best_only=True, mode='min')\n",
        "        #     history = model.fit(X_train, y_train, epochs=epochs_dec_def, batch_size=batch_size, verbose=verbose, callbacks=[checkpoint], shuffle=False, validation_data=val_data)\n",
        "    else:\n",
        "        checkpoint = ModelCheckpoint(filepath=f'{save_path}/{date}/{name}.h5', monitor='val_loss', verbose=verbose, save_best_only=True, mode='min')\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', start_from_epoch=80, patience=10), checkpoint]    # EarlyStopping: 如果從第 80 個 epoch 開始超過 10 個 epoch 都沒有降低 loss 就提早停止\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=callbacks, shuffle=False, validation_data=val_data)\n",
        "\n",
        "\n",
        "    #----------------------- Save the training history (loss and mae) as .pkl -----------------------\n",
        "    pickle.dump(history.history, open(f'{save_path}/{date}/{name}_history.pkl', 'wb'))\n",
        "\n",
        "\n",
        "    del model\n"
      ],
      "metadata": {
        "id": "6hnIKfZ1iSOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.2.3 預先訓練多個模型並儲存**\n"
      ],
      "metadata": {
        "id": "MZ7gXessL1Dq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZRLDs6TL2Ap"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# 訓練並儲存模型\n",
        "def trainMonthlyRevenueNN(data: pd.DataFrame, y_test_start_yr: int, y_test_start_mon: int, y_test_end_yr: int, y_test_end_mon: int, modelName: str, save_path: str, industry_data = None, encoded: bool = False):\n",
        "    '''\n",
        "    預先訓練並儲存模型。\n",
        "    \n",
        "    Parameters\n",
        "    ----------    \n",
        "    data: 資料集, \n",
        "    y_test_start_yr: 預測起始年, y_test_start_mon: 預測起始月, \n",
        "    y_test_end_yr: 預測終止年, y_test_end_mon: 預測終止月, \n",
        "    modelName: | 'rnn' | 'lstm' |, \n",
        "    save_path: 模型欲儲存的位置,\n",
        "    industry_data: 產業變數，default = None (不加入產業變數)\n",
        "    encoded: 產業變數是否要使用 target encoding (default = False)\n",
        "    '''\n",
        "\n",
        "    test_y_m = month_range(y_test_start_yr, y_test_start_mon, y_test_end_yr, y_test_end_mon)  # 所有要預測的年月\n",
        "    back_most = 48    # 以前48個月的資料預測第t期\n",
        "\n",
        "    # 針對每個欲預測的年月\n",
        "    for i in test_y_m:\n",
        "        start = time.time()\n",
        "\n",
        "        y_test_yr = int(i.split(\"-\")[0])    # 預測的年\n",
        "        y_test_mon = int(i.split(\"-\")[1])   # 預測的月\n",
        "\n",
        "        #-----------------------取得訓練資料集-----------------------\n",
        "        # 原始資料\n",
        "        X_train, y_train, X_test, y_test = get_train_test(data, y_test_yr, y_test_mon, back_most, y_back=12)    # y_train 為 y_test 往前推 12 個月\n",
        "\n",
        "        # 拆解資料\n",
        "        trend_train, season_train, resid_train = decompose_data(X_train)\n",
        "        X_train_dec = pd.concat([trend_train, season_train, resid_train], axis=1)\n",
        "\n",
        "        # 消除 seasonal effect\n",
        "        season_train.columns = X_train.columns.copy()\n",
        "        X_train_season = X_train - season_train\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        if industry_data is not None:\n",
        "            X_train = add_industry(X_train, industry_data, encoded)\n",
        "            X_train_dec = add_industry(X_train_dec, industry_data, encoded)\n",
        "            X_train_season = add_industry(X_train_season, industry_data, encoded)\n",
        "\n",
        "        #-----------------------取得平減（標準化）訓練資料集-----------------------\n",
        "        # 平減資料（標準化資料）\n",
        "        mean_train, min_train, max_train, std_train, X_train_def = standardize_X(X_train)\n",
        "        y_train_def = standardize_y(mean_train, min_train, max_train, std_train, y_train)\n",
        "\n",
        "        # 拆解 + 平減資料（標準化資料）\n",
        "        mean_train_dec, min_train_dec, max_train_dec, std_train_dec, X_train_dec_def = standardize_X(X_train_dec)\n",
        "        y_train_dec_def = standardize_y(mean_train_dec, min_train_dec, max_train_dec, std_train_dec, y_train)\n",
        "\n",
        "        # 消除 seasonal effect + 平減資料（標準化資料）\n",
        "        mean_train_season, min_train_season, max_train_season, std_train_season, X_train_season_def = standardize_X(X_train_season)\n",
        "        y_train_season_def = standardize_y(mean_train_season, min_train_season, max_train_season, std_train_season, y_train)\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        # if industry_data is not None:\n",
        "        #     X_train = add_industry(X_train, industry_data, encoded)\n",
        "        #     X_train_dec = add_industry(X_train_dec, industry_data, encoded)\n",
        "        #     X_train_season = add_industry(X_train_season, industry_data, encoded)\n",
        "        #     X_train_def = add_industry(X_train_def, industry_data, encoded)\n",
        "        #     X_train_dec_def = add_industry(X_train_dec_def, industry_data, encoded)\n",
        "        #     X_train_season_def = add_industry(X_train_season_def, industry_data, encoded)\n",
        "\n",
        "        #-----------------------Reshape X 訓練資料集-----------------------\n",
        "        X_train, X_train_def, X_train_dec, X_train_dec_def, X_train_season, X_train_season_def = reshapeInputNNforAll(X_train, X_train_def, X_train_dec, X_train_dec_def, X_train_season, X_train_season_def)\n",
        "        \n",
        "        #-----------------------模型訓練與儲存-----------------------\n",
        "        trainModelNN(modelName, X_train, y_train, save_path, i, 'model')\n",
        "        trainModelNN(modelName, X_train_def, y_train_def, save_path, i, 'def_model')\n",
        "        trainModelNN(modelName, X_train_dec, y_train, save_path, i, 'dec_model')\n",
        "        trainModelNN(modelName, X_train_dec_def, y_train_dec_def, save_path, i, 'dec_def_model')\n",
        "        trainModelNN(modelName, X_train_season, y_train, save_path, i, 'season_model')\n",
        "        trainModelNN(modelName, X_train_season_def, y_train_season_def, save_path, i, 'season_def_model')\n",
        " \n",
        "        print(f\"{i} model saved. Using time:\", \"%.3f\"%(time.time() - start), \" secs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.2.4 Training History**\n"
      ],
      "metadata": {
        "id": "vxA0rxKC9pRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotTrainingHistory(save_path: str, date: str, name: str, loss_mae = False):\n",
        "    '''\n",
        "    Plot training history of Y-m.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    save_path: 模型和歷史資料儲存的位置\n",
        "    date: 預測的某個年月\n",
        "    name: 模型檔名\n",
        "    loss_mae: loss 是否為 MAE (default = False)\n",
        "    '''\n",
        "    model_history = pickle.load(open(f'{save_path}/{date}/{name}_history.pkl', 'rb'))\n",
        "    hist_loss = model_history['loss']\n",
        "\n",
        "    if loss_mae == True:    # 2023.04.16\n",
        "        hist_score = model_history['mse']\n",
        "        title_loss = 'MAE'  \n",
        "        title_score = 'MSE' \n",
        "    else:\n",
        "        hist_score = model_history['mae']\n",
        "        title_loss = 'MSE'  \n",
        "        title_score = 'MAE' \n",
        "\n",
        "    plt.figure(figsize = (15,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title(f\"Loss ({title_loss}) of Training Set\")\n",
        "    plt.plot(range(0, len(hist_loss)), hist_loss)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title(f\"{title_score} of Training Set\")\n",
        "    plt.plot(range(0, len(hist_score)), hist_score)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YFXVHoG79zGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Predicting and Evaluation**\n",
        "\n",
        "衡量指標：\n",
        "\n",
        "*   RMSE (Root Mean Square Error)\n",
        "\n",
        "$$RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(\\hat{y}_i - y_i)^2}$$\n",
        "\n",
        "<br>\n",
        "\n",
        "*   MAE (Mean Absolute Error)\n",
        "\n",
        "$$MAE = \\frac{1}{n}\\sum_{i=1}^n|\\hat{y}_i - y_i|$$\n",
        "\n",
        "<br>\n",
        "\n",
        "*   MAE% (MAE / mean of the sum of y_true)\n",
        "\n",
        "$$MAE\\% = \\frac{\\frac{1}{n}\\sum_{i=1}^n|\\hat{y}_i - y_i|}{\\frac{1}{n}\\sum_{i=1}^n y_i} = \\frac{\\sum_{i=1}^n|\\hat{y}_i - y_i|}{\\sum_{i=1}^n y_i}$$\n",
        "\n",
        "<br>\n",
        "\n",
        "*   MAPE (Mean Absolute Percentage Error)\n",
        "\n",
        "$$MAPE(\\%) = \\frac{1}{n}\\sum_{i=1}^n \\frac{|\\hat{y}_i - y_i|}{y_i}$$\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "0cyJa68O8cmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1 評估預測結果**"
      ],
      "metadata": {
        "id": "Ti7RZPUi5kZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評估預測結果好壞\n",
        "def evaluatePerformance(y_true, y_pred, rmse: list, mae: list, mae_percent: list, mape: list):\n",
        "    '''\n",
        "    評估預測結果好壞。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true: 真實月營收, y_pred: 預測月營收, \n",
        "    rmse, mae, mae_percent, mape: 用來儲存各種衡量指標預測分數的 list\n",
        "    ''' \n",
        "    rmse.append(round(mean_squared_error(y_true, y_pred, squared=False), 0))\n",
        "    mae.append(round(mean_absolute_error(y_true, y_pred), 0))\n",
        "    mae_percent.append(round(mean_absolute_error(y_true, y_pred) / y_true.mean(), 4))\n",
        "    mape.append(round(mean_absolute_percentage_error(y_true, y_pred), 4))\n",
        "\n",
        "# 彙整不同衡量指標的預測分數 \n",
        "def savePerformace(scoresD, rmse: list, mae: list, mae_percent: list, mape: list, dataName: str):  \n",
        "    '''\n",
        "    彙整不同衡量指標的預測分數。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    scoresD: 彙整所有分數的 dataframe, \n",
        "    rmse, mae, mae_percent, mape: 各種衡量指標的預測分數, \n",
        "    dataName: | 'org' | 'def' | 'dec' | 'dec_def' | 'season' | 'season_def' |\n",
        "    ''' \n",
        "    scoresD[f'RMSE-{dataName}'] = rmse\n",
        "    scoresD[f'MAE-{dataName}'] = mae\n",
        "    scoresD[f'MAE%-{dataName}'] = mae_percent\n",
        "    scoresD[f'MAPE-{dataName}'] = mape"
      ],
      "metadata": {
        "id": "9Y-PLUYS9X0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2 Random Forest & XGB**"
      ],
      "metadata": {
        "id": "Qd3prhSM5gHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm80lc3v-KDw"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# 預測並儲存結果\n",
        "def predictMonthlyRevenue(data: pd.DataFrame, y_test_start_yr: int, y_test_start_mon: int, y_test_end_yr: int, y_test_end_mon: int, modelName: str, save_path: str, industry_data = None, encoded: bool = False):\n",
        "    '''\n",
        "    預測月營收。\n",
        "    \n",
        "    Parameters\n",
        "    ----------    \n",
        "    data: 資料集, \n",
        "    y_test_start_yr: 預測起始年, y_test_start_mon: 預測起始月, \n",
        "    y_test_end_yr: 預測終止年, y_test_end_mon: 預測終止月, \n",
        "    modelName: | 'rf' | 'xgb' |, \n",
        "    save_path: 模型儲存的位置,\n",
        "    industry_data: 產業變數，default = None (不加入產業變數)\n",
        "    encoded: 產業變數是否要使用 target encoding (default = False)\n",
        "\n",
        "    Returns\n",
        "    ----------    \n",
        "    pred = \n",
        "    {\"org\": {\"org\": org_pred, \"dec\": dec_pred, \"season\": season_pred},\n",
        "     \"def\": {\"org\": def_pred, \"dec\": dec_def_pred, \"season\": season_def_pred}\n",
        "    },\n",
        "    \n",
        "    feature_importance = \n",
        "    {\"org\": {\"org\": feature_importance, \"dec\": feature_importance_dec, \"season\": feature_importance_season},\n",
        "     \"def\": {\"org\": feature_importance_def, \"dec\": feature_importance_dec_def, \"season\": feature_importance_season_def}\n",
        "    },\n",
        "\n",
        "    scores\n",
        "    '''\n",
        "\n",
        "    start = time.time()\n",
        "    test_y_m = month_range(y_test_start_yr, y_test_start_mon, y_test_end_yr, y_test_end_mon)  # 所有要預測的年月\n",
        "    back_most = 48    # 以前48個月的資料預測第t期\n",
        "    cv = 5\n",
        "\n",
        "    org_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄原始資料的預測值\n",
        "    feature_importance = pd.DataFrame()                         # 紀錄模型所計算出的 feature importance\n",
        "    def_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄平減資料的預測值\n",
        "    feature_importance_def = pd.DataFrame()                     # 紀錄模型所計算出的 feature importance\n",
        "\n",
        "    dec_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄拆解資料的預測值\n",
        "    feature_importance_dec = pd.DataFrame()                     # 紀錄模型所計算出的 feature importance\n",
        "    dec_def_pred = pd.DataFrame(index=data.index.tolist())      # 紀錄拆解資料+平減的預測值\n",
        "    feature_importance_dec_def = pd.DataFrame()                 # 紀錄模型所計算出的 feature importance\n",
        "\n",
        "    season_pred = pd.DataFrame(index=data.index.tolist())       # 紀錄消除 seasonal effect 資料的預測值\n",
        "    feature_importance_season = pd.DataFrame()                  # 紀錄模型所計算出的 feature importance\n",
        "    season_def_pred = pd.DataFrame(index=data.index.tolist())   # 紀錄消除 seasonal effect + 平減資料的預測值\n",
        "    feature_importance_season_def = pd.DataFrame()              # 紀錄模型所計算出的 feature importance\n",
        "\n",
        "    # 紀錄原始資料的預測分數\n",
        "    rmse_list = []\n",
        "    mae_list = []\n",
        "    mae_percent_list = []\n",
        "    mape_list = []\n",
        "\n",
        "    # 紀錄平減資料的預測分數\n",
        "    rmse_list_def = []\n",
        "    mae_list_def = []\n",
        "    mae_percent_list_def = []\n",
        "    mape_list_def = []\n",
        "\n",
        "    # 紀錄拆解資料的預測分數\n",
        "    rmse_list_dec = []\n",
        "    mae_list_dec = []\n",
        "    mae_percent_list_dec = []\n",
        "    mape_list_dec = []\n",
        "\n",
        "    # 紀錄拆解+平減資料的預測分數\n",
        "    rmse_list_dec_def = []\n",
        "    mae_list_dec_def = []\n",
        "    mae_percent_list_dec_def = []\n",
        "    mape_list_dec_def = []\n",
        "\n",
        "    # 紀錄消除 seasonal effect 資料的預測分數\n",
        "    rmse_list_season = []\n",
        "    mae_list_season = []\n",
        "    mae_percent_list_season = []\n",
        "    mape_list_season = []\n",
        "\n",
        "    # 紀錄消除 seasonal effect + 平減資料的預測分數\n",
        "    rmse_list_season_def = []\n",
        "    mae_list_season_def = []\n",
        "    mae_percent_list_season_def = []\n",
        "    mape_list_season_def = []\n",
        "\n",
        "    # 彙整所有預測分數\n",
        "    scores = pd.DataFrame(index=test_y_m)\n",
        "\n",
        "    # To fix fragmented problem (2023.04.08)\n",
        "    counter = 1\n",
        "\n",
        "    # 針對每個欲預測的年月\n",
        "    for i in test_y_m:\n",
        "\n",
        "        y_test_yr = int(i.split(\"-\")[0])    # 預測的年\n",
        "        y_test_mon = int(i.split(\"-\")[1])   # 預測的月\n",
        "\n",
        "        #-----------------------取得測試資料集-----------------------\n",
        "        # 原始資料\n",
        "        X_train, y_train, X_test, y_test = get_train_test(data, y_test_yr, y_test_mon, back_most, y_back=12)    # y_train 為 y_test 往前推 12 個月\n",
        "\n",
        "        # 拆解資料\n",
        "        trend_test, season_test, resid_test = decompose_data(X_test)\n",
        "        X_test_dec = pd.concat([trend_test, season_test, resid_test], axis=1)\n",
        "\n",
        "        # 消除 seasonal effect\n",
        "        season_test.columns = X_test.columns.copy()     # Column name 相同才能相減  \n",
        "        X_test_season = X_test - season_test\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        if industry_data is not None:\n",
        "            X_test = add_industry(X_test, industry_data, encoded)\n",
        "            X_test_dec = add_industry(X_test_dec, industry_data, encoded)\n",
        "            X_test_season = add_industry(X_test_season, industry_data, encoded)\n",
        "\n",
        "        #-----------------------取得平減（標準化）測試資料集-----------------------\n",
        "        # 平減資料（標準化資料）\n",
        "        mean_test, min_test, max_test, std_test, X_test_def = standardize_X(X_test)\n",
        "\n",
        "        # 拆解 + 平減資料（標準化資料）\n",
        "        mean_test_dec, min_test_dec, max_test_dec, std_test_dec, X_test_dec_def = standardize_X(X_test_dec)\n",
        "       \n",
        "        # 消除 seasonal effect + 平減資料（標準化資料）\n",
        "        mean_test_season, min_test_season, max_test_season, std_test_season, X_test_season_def = standardize_X(X_test_season)\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        # if industry_data is not None:\n",
        "        #     X_test = add_industry(X_test, industry_data, encoded)\n",
        "        #     X_test_dec = add_industry(X_test_dec, industry_data, encoded)\n",
        "        #     X_test_season = add_industry(X_test_season, industry_data, encoded)\n",
        "        #     X_test_def = add_industry(X_test_def, industry_data, encoded)\n",
        "        #     X_test_dec_def = add_industry(X_test_dec_def, industry_data, encoded)\n",
        "        #     X_test_season_def = add_industry(X_test_season_def, industry_data, encoded)\n",
        "        \n",
        "        #-----------------------取得已訓練好的模型-----------------------\n",
        "        model = pickle.load(open(f'{save_path}/{i}/model.pkl', 'rb'))\n",
        "        def_model = pickle.load(open(f'{save_path}/{i}/def_model.pkl', 'rb'))\n",
        "        dec_model = pickle.load(open(f'{save_path}/{i}/dec_model.pkl', 'rb'))\n",
        "        dec_def_model = pickle.load(open(f'{save_path}/{i}/dec_def_model.pkl', 'rb'))\n",
        "        season_model = pickle.load(open(f'{save_path}/{i}/season_model.pkl', 'rb'))\n",
        "        season_def_model = pickle.load(open(f'{save_path}/{i}/season_def_model.pkl', 'rb'))\n",
        "\n",
        "        #-----------------------儲存預測值-----------------------\n",
        "        org_pred[i] = np.round(model.predict(X_test), 0)\n",
        "        def_pred[i] = np.round(standardized_y_back(mean_test, min_test, max_test, std_test, def_model.predict(X_test_def)), 0)   # 將標準化的預測值轉換回原始值\n",
        "        dec_pred[i] = np.round(dec_model.predict(X_test_dec), 0)\n",
        "        dec_def_pred[i] = np.round(standardized_y_back(mean_test_dec, min_test_dec, max_test_dec, std_test_dec, dec_def_model.predict(X_test_dec_def)), 0)   # 將標準化的預測值轉換回原始值\n",
        "        season_pred[i] = np.round(season_model.predict(X_test_season), 0)\n",
        "        season_def_pred[i] = np.round(standardized_y_back(mean_test_season, min_test_season, max_test_season, std_test_season, season_def_model.predict(X_test_season_def)), 0)   # 將標準化的預測值轉換回原始值\n",
        "\n",
        "        # To fix fragmented problem (2023.04.08)\n",
        "        if counter == 100:\n",
        "            org_pred = org_pred.copy()\n",
        "            def_pred = def_pred.copy()\n",
        "            dec_pred = dec_pred.copy()\n",
        "            dec_def_pred = dec_def_pred.copy()\n",
        "            season_pred = season_pred.copy()\n",
        "            season_def_pred = season_def_pred.copy()\n",
        "\n",
        "        #-----------------------儲存變數重要性-----------------------\n",
        "        feature_importance[i] = np.round(model.feature_importances_, 4)\n",
        "        feature_importance_def[i] = np.round(def_model.feature_importances_, 4)\n",
        "        feature_importance_dec[i] = np.round(dec_model.feature_importances_, 4)\n",
        "        feature_importance_dec_def[i] = np.round(dec_def_model.feature_importances_, 4)\n",
        "        feature_importance_season[i] = np.round(season_model.feature_importances_, 4)\n",
        "        feature_importance_season_def[i] = np.round(season_def_model.feature_importances_, 4)\n",
        "\n",
        "        # To fix fragmented problem (2023.04.08)\n",
        "        if counter == 100:\n",
        "            feature_importance = feature_importance.copy()\n",
        "            feature_importance_def = feature_importance_def.copy()\n",
        "            feature_importance_dec = feature_importance_dec.copy()\n",
        "            feature_importance_dec_def = feature_importance_dec_def.copy()\n",
        "            feature_importance_season = feature_importance_season.copy()\n",
        "            feature_importance_season_def = feature_importance_season_def.copy()\n",
        "\n",
        "        #-----------------------儲存預測分數-----------------------\n",
        "        evaluatePerformance(y_test, org_pred[i], rmse_list, mae_list, mae_percent_list, mape_list)\n",
        "        evaluatePerformance(y_test, def_pred[i], rmse_list_def, mae_list_def, mae_percent_list_def, mape_list_def)\n",
        "        evaluatePerformance(y_test, dec_pred[i], rmse_list_dec, mae_list_dec, mae_percent_list_dec, mape_list_dec)\n",
        "        evaluatePerformance(y_test, dec_def_pred[i], rmse_list_dec_def, mae_list_dec_def, mae_percent_list_dec_def, mape_list_dec_def)\n",
        "        evaluatePerformance(y_test, season_pred[i], rmse_list_season, mae_list_season, mae_percent_list_season, mape_list_season)\n",
        "        evaluatePerformance(y_test, season_def_pred[i], rmse_list_season_def, mae_list_season_def, mae_percent_list_season_def, mape_list_season_def)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "    # Set feature names\n",
        "    feature_importance.index = model.feature_names_in_\n",
        "    feature_importance_def.index = def_model.feature_names_in_\n",
        "    feature_importance_dec.index = dec_model.feature_names_in_\n",
        "    feature_importance_dec_def.index = dec_def_model.feature_names_in_\n",
        "    feature_importance_season.index = season_model.feature_names_in_\n",
        "    feature_importance_season_def.index = season_def_model.feature_names_in_\n",
        "\n",
        "    # 彙整不同衡量指標的預測分數\n",
        "    savePerformace(scores, rmse_list, mae_list, mae_percent_list, mape_list, 'org')\n",
        "    savePerformace(scores, rmse_list_def, mae_list_def, mae_percent_list_def, mape_list_def, 'def')\n",
        "    savePerformace(scores, rmse_list_dec, mae_list_dec, mae_percent_list_dec, mape_list_dec, 'dec')\n",
        "    savePerformace(scores, rmse_list_dec_def, mae_list_dec_def, mae_percent_list_dec_def, mape_list_dec_def, 'dec_def')\n",
        "    savePerformace(scores, rmse_list_season, mae_list_season, mae_percent_list_season, mape_list_season, 'season')\n",
        "    savePerformace(scores, rmse_list_season_def, mae_list_season_def, mae_percent_list_season_def, mape_list_season_def, 'season_def')\n",
        "\n",
        "    # 將所有預測結果、變數重要性分別存在 dictionary 中 (2023.04.04 updated)\n",
        "    pred = {\"org\": {\"org\": org_pred,\n",
        "                    \"dec\": dec_pred,\n",
        "                    \"season\": season_pred\n",
        "                    },\n",
        "            \"def\": {\"org\": def_pred,\n",
        "                    \"dec\": dec_def_pred,\n",
        "                    \"season\": season_def_pred\n",
        "                    }\n",
        "            }\n",
        "\n",
        "    feature_importance = {\"org\": {\"org\": feature_importance,\n",
        "                                  \"dec\": feature_importance_dec,\n",
        "                                  \"season\": feature_importance_season\n",
        "                                  },\n",
        "                          \"def\": {\"org\": feature_importance_def,\n",
        "                                  \"dec\": feature_importance_dec_def,\n",
        "                                  \"season\": feature_importance_season_def\n",
        "                                  }\n",
        "                          }\n",
        "\n",
        "    print(\"Using time:\", \"%.3f\"%(time.time() - start), \" secs.\")\n",
        "\n",
        "    return pred, feature_importance, scores\n",
        "\n",
        "    # return org_pred, feature_importance, def_pred, feature_importance_def, dec_pred, feature_importance_dec, dec_def_pred, feature_importance_dec_def, season_pred, feature_importance_season, season_def_pred, feature_importance_season_def, scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3 RNN & LSTM**\n",
        "\n",
        "2023.04.14"
      ],
      "metadata": {
        "id": "bp2Am7Hh54YP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqrmV7oH52yh"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# 預測並儲存結果\n",
        "def predictMonthlyRevenueNN(data: pd.DataFrame, y_test_start_yr: int, y_test_start_mon: int, y_test_end_yr: int, y_test_end_mon: int, modelName: str, save_path: str, industry_data = None, encoded: bool = False):\n",
        "    '''\n",
        "    預測月營收。\n",
        "    \n",
        "    Parameters\n",
        "    ----------    \n",
        "    data: 資料集, \n",
        "    y_test_start_yr: 預測起始年, y_test_start_mon: 預測起始月, \n",
        "    y_test_end_yr: 預測終止年, y_test_end_mon: 預測終止月, \n",
        "    modelName: | 'rnn' | 'lstm' |, \n",
        "    save_path: 模型儲存的位置,\n",
        "    industry_data: 產業變數，default = None (不加入產業變數)\n",
        "    encoded: 產業變數是否要使用 target encoding (default = False)\n",
        "\n",
        "    Returns\n",
        "    ----------    \n",
        "    pred = \n",
        "    {\"org\": {\"org\": org_pred, \"dec\": dec_pred, \"season\": season_pred},\n",
        "     \"def\": {\"org\": def_pred, \"dec\": dec_def_pred, \"season\": season_def_pred}\n",
        "    },\n",
        "\n",
        "    scores\n",
        "    '''\n",
        "\n",
        "    start = time.time()\n",
        "    test_y_m = month_range(y_test_start_yr, y_test_start_mon, y_test_end_yr, y_test_end_mon)  # 所有要預測的年月\n",
        "    back_most = 48    # 以前48個月的資料預測第t期\n",
        "    cv = 5\n",
        "\n",
        "    org_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄原始資料的預測值\n",
        "    def_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄平減資料的預測值\n",
        "\n",
        "    dec_pred = pd.DataFrame(index=data.index.tolist())          # 紀錄拆解資料的預測值\n",
        "    dec_def_pred = pd.DataFrame(index=data.index.tolist())      # 紀錄拆解資料+平減的預測值\n",
        "\n",
        "    season_pred = pd.DataFrame(index=data.index.tolist())       # 紀錄消除 seasonal effect 資料的預測值\n",
        "    season_def_pred = pd.DataFrame(index=data.index.tolist())   # 紀錄消除 seasonal effect + 平減資料的預測值\n",
        "\n",
        "    # 紀錄原始資料的預測分數\n",
        "    rmse_list = []\n",
        "    mae_list = []\n",
        "    mae_percent_list = []\n",
        "    mape_list = []\n",
        "\n",
        "    # 紀錄平減資料的預測分數\n",
        "    rmse_list_def = []\n",
        "    mae_list_def = []\n",
        "    mae_percent_list_def = []\n",
        "    mape_list_def = []\n",
        "\n",
        "    # 紀錄拆解資料的預測分數\n",
        "    rmse_list_dec = []\n",
        "    mae_list_dec = []\n",
        "    mae_percent_list_dec = []\n",
        "    mape_list_dec = []\n",
        "\n",
        "    # 紀錄拆解+平減資料的預測分數\n",
        "    rmse_list_dec_def = []\n",
        "    mae_list_dec_def = []\n",
        "    mae_percent_list_dec_def = []\n",
        "    mape_list_dec_def = []\n",
        "\n",
        "    # 紀錄消除 seasonal effect 資料的預測分數\n",
        "    rmse_list_season = []\n",
        "    mae_list_season = []\n",
        "    mae_percent_list_season = []\n",
        "    mape_list_season = []\n",
        "\n",
        "    # 紀錄消除 seasonal effect + 平減資料的預測分數\n",
        "    rmse_list_season_def = []\n",
        "    mae_list_season_def = []\n",
        "    mae_percent_list_season_def = []\n",
        "    mape_list_season_def = []\n",
        "\n",
        "    # 彙整所有預測分數\n",
        "    scores = pd.DataFrame(index=test_y_m)\n",
        "\n",
        "    # To fix fragmented problem\n",
        "    counter = 1\n",
        "\n",
        "    # 針對每個欲預測的年月\n",
        "    for i in test_y_m:\n",
        "\n",
        "        y_test_yr = int(i.split(\"-\")[0])    # 預測的年\n",
        "        y_test_mon = int(i.split(\"-\")[1])   # 預測的月\n",
        "\n",
        "        #-----------------------取得測試資料集-----------------------\n",
        "        # 原始資料\n",
        "        X_train, y_train, X_test, y_test = get_train_test(data, y_test_yr, y_test_mon, back_most, y_back=12)    # y_train 為 y_test 往前推 12 個月\n",
        "\n",
        "        # 拆解資料\n",
        "        trend_test, season_test, resid_test = decompose_data(X_test)\n",
        "        X_test_dec = pd.concat([trend_test, season_test, resid_test], axis=1)\n",
        "\n",
        "        # 消除 seasonal effect\n",
        "        season_test.columns = X_test.columns.copy()     # Column name 相同才能相減  \n",
        "        X_test_season = X_test - season_test\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        if industry_data is not None:\n",
        "            X_test = add_industry(X_test, industry_data, encoded)\n",
        "            X_test_dec = add_industry(X_test_dec, industry_data, encoded)\n",
        "            X_test_season = add_industry(X_test_season, industry_data, encoded)\n",
        "\n",
        "        #-----------------------取得平減（標準化）測試資料集-----------------------\n",
        "        # 平減資料（標準化資料）\n",
        "        mean_test, min_test, max_test, std_test, X_test_def = standardize_X(X_test)\n",
        "\n",
        "        # 拆解 + 平減資料（標準化資料）\n",
        "        mean_test_dec, min_test_dec, max_test_dec, std_test_dec, X_test_dec_def = standardize_X(X_test_dec)\n",
        "\n",
        "        # 消除 seasonal effect + 平減資料（標準化資料）\n",
        "        mean_test_season, min_test_season, max_test_season, std_test_season, X_test_season_def = standardize_X(X_test_season)\n",
        "\n",
        "        #-----------------------加入產業變數 (2023.05.04)-----------------------\n",
        "        # if industry_data is not None:\n",
        "        #     X_test = add_industry(X_test, industry_data, encoded)\n",
        "        #     X_test_dec = add_industry(X_test_dec, industry_data, encoded)\n",
        "        #     X_test_season = add_industry(X_test_season, industry_data, encoded)\n",
        "        #     X_test_def = add_industry(X_test_def, industry_data, encoded)\n",
        "        #     X_test_dec_def = add_industry(X_test_dec_def, industry_data, encoded)\n",
        "        #     X_test_season_def = add_industry(X_test_season_def, industry_data, encoded)\n",
        "\n",
        "        #-----------------------Reshape X 測試資料集-----------------------\n",
        "        X_test, X_test_def, X_test_dec, X_test_dec_def, X_test_season, X_test_season_def = reshapeInputNNforAll(X_test, X_test_def, X_test_dec, X_test_dec_def, X_test_season, X_test_season_def)\n",
        "        \n",
        "        #-----------------------取得已訓練好的模型-----------------------\n",
        "        model = load_model(f'{save_path}/{i}/model.h5')\n",
        "        def_model = load_model(f'{save_path}/{i}/def_model.h5')\n",
        "        dec_model = load_model(f'{save_path}/{i}/dec_model.h5')\n",
        "        dec_def_model = load_model(f'{save_path}/{i}/dec_def_model.h5')\n",
        "        season_model = load_model(f'{save_path}/{i}/season_model.h5')\n",
        "        season_def_model = load_model(f'{save_path}/{i}/season_def_model.h5')\n",
        "\n",
        "        #-----------------------儲存預測值-----------------------\n",
        "        org_pred[i] = np.round(model.predict(X_test, verbose=verbose), 0)\n",
        "        def_pred[i] = np.round(standardized_y_back(mean_test, min_test, max_test, std_test, def_model.predict(X_test_def, verbose=verbose)), 0)   # 將標準化的預測值轉換回原始值\n",
        "        dec_pred[i] = np.round(dec_model.predict(X_test_dec, verbose=verbose), 0)\n",
        "        dec_def_pred[i] = np.round(standardized_y_back(mean_test_dec, min_test_dec, max_test_dec, std_test_dec, dec_def_model.predict(X_test_dec_def, verbose=verbose)), 0)   # 將標準化的預測值轉換回原始值\n",
        "        season_pred[i] = np.round(season_model.predict(X_test_season, verbose=verbose), 0)\n",
        "        season_def_pred[i] = np.round(standardized_y_back(mean_test_season, min_test_season, max_test_season, std_test_season, season_def_model.predict(X_test_season_def, verbose=verbose)), 0)   # 將標準化的預測值轉換回原始值\n",
        "\n",
        "        # To fix fragmented problem\n",
        "        if counter == 100:\n",
        "            org_pred = org_pred.copy()\n",
        "            def_pred = def_pred.copy()\n",
        "            dec_pred = dec_pred.copy()\n",
        "            dec_def_pred = dec_def_pred.copy()\n",
        "            season_pred = season_pred.copy()\n",
        "            season_def_pred = season_def_pred.copy()\n",
        "\n",
        "        #-----------------------儲存預測分數-----------------------\n",
        "        evaluatePerformance(y_test, org_pred[i], rmse_list, mae_list, mae_percent_list, mape_list)\n",
        "        evaluatePerformance(y_test, def_pred[i], rmse_list_def, mae_list_def, mae_percent_list_def, mape_list_def)\n",
        "        evaluatePerformance(y_test, dec_pred[i], rmse_list_dec, mae_list_dec, mae_percent_list_dec, mape_list_dec)\n",
        "        evaluatePerformance(y_test, dec_def_pred[i], rmse_list_dec_def, mae_list_dec_def, mae_percent_list_dec_def, mape_list_dec_def)\n",
        "        evaluatePerformance(y_test, season_pred[i], rmse_list_season, mae_list_season, mae_percent_list_season, mape_list_season)\n",
        "        evaluatePerformance(y_test, season_def_pred[i], rmse_list_season_def, mae_list_season_def, mae_percent_list_season_def, mape_list_season_def)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "    # 彙整不同衡量指標的預測分數\n",
        "    savePerformace(scores, rmse_list, mae_list, mae_percent_list, mape_list, 'org')\n",
        "    savePerformace(scores, rmse_list_def, mae_list_def, mae_percent_list_def, mape_list_def, 'def')\n",
        "    savePerformace(scores, rmse_list_dec, mae_list_dec, mae_percent_list_dec, mape_list_dec, 'dec')\n",
        "    savePerformace(scores, rmse_list_dec_def, mae_list_dec_def, mae_percent_list_dec_def, mape_list_dec_def, 'dec_def')\n",
        "    savePerformace(scores, rmse_list_season, mae_list_season, mae_percent_list_season, mape_list_season, 'season')\n",
        "    savePerformace(scores, rmse_list_season_def, mae_list_season_def, mae_percent_list_season_def, mape_list_season_def, 'season_def')\n",
        "\n",
        "    # 將所有預測結果、變數重要性分別存在 dictionary 中\n",
        "    pred = {\"org\": {\"org\": org_pred,\n",
        "                    \"dec\": dec_pred,\n",
        "                    \"season\": season_pred\n",
        "                    },\n",
        "            \"def\": {\"org\": def_pred,\n",
        "                    \"dec\": dec_def_pred,\n",
        "                    \"season\": season_def_pred\n",
        "                    }\n",
        "            }\n",
        "\n",
        "    print(\"Using time:\", \"%.3f\"%(time.time() - start), \" secs.\")\n",
        "\n",
        "    return pred, scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Best and Worst Model**"
      ],
      "metadata": {
        "id": "tx48nPLSWN6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.1 Random Forest & XGB**\n",
        "\n",
        "2023.04.05"
      ],
      "metadata": {
        "id": "YzYnm09mbQxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BestWorstModel():\n",
        "    '''\n",
        "    找出最好和最差模型。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    best_rf, worst_rf: dict\n",
        "        Random Forest 在各個衡量指標下最好和最差的模型。\n",
        "    best_xgb, worst_xgb: dict\n",
        "        XGB 在各個衡量指標下最好和最差的模型。\n",
        "    best_all, worst_all: dict\n",
        "        所有模型中，在各個衡量指標下最好和最差的模型。\n",
        "    ----------\n",
        "    best_worst_rf, best_worst_xgb: pd.DataFrame\n",
        "        各資料處理方式中，預測最好和最差的月份。\n",
        "    best_worst: pd.DataFrame\n",
        "        各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "\n",
        "    Methods\n",
        "    ----------\n",
        "    findBestWorstForAll(scoreType: str): \n",
        "        根據所選擇的衡量指標，找出各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, score_rf: pd.DataFrame, score_xgb: pd.DataFrame):\n",
        "        self.score_rf = score_rf\n",
        "        self.score_xgb = score_xgb\n",
        "        self.best_worst_rf, self.best_worst_xgb, self.best_worst = self.createBestWorstForAll()\n",
        "        self.best_rf, self.worst_rf = self.findBestWorstByModel('rf')\n",
        "        self.best_xgb, self.worst_xgb = self.findBestWorstByModel('xgb')\n",
        "        self.best_all, self.worst_all = self.findBestWorstByModel('all')\n",
        "\n",
        "    def createBestWorstForAll(self):\n",
        "        '''\n",
        "        各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "        '''\n",
        "        best_worst_rf = pd.DataFrame(columns = ['modelName', 'dataType', 'scoreType', 'min_month', 'min_score', 'max_month', 'max_score'])\n",
        "        best_worst_xgb = pd.DataFrame(columns = ['modelName', 'dataType', 'scoreType', 'min_month', 'min_score', 'max_month', 'max_score'])\n",
        "\n",
        "        # Random Forest\n",
        "        for colName, colData in self.score_rf.items():\n",
        "            best_worst_rf.loc[len(best_worst_rf)] = ['Random Forest', colName.split(\"-\")[-1], colName.split(\"-\")[0], colData.idxmin(), colData.min(), colData.idxmax(), colData.max()]\n",
        "        # XGB\n",
        "        for colName, colData in self.score_xgb.items():\n",
        "            best_worst_xgb.loc[len(best_worst_xgb)] = ['XGB', colName.split(\"-\")[-1], colName.split(\"-\")[0], colData.idxmin(), colData.min(), colData.idxmax(), colData.max()]\n",
        "        \n",
        "        # All\n",
        "        best_worst = pd.concat([best_worst_rf, best_worst_xgb])\n",
        "\n",
        "        # Sort by scoreType\n",
        "        best_worst_rf.sort_values(by=['scoreType'])\n",
        "        best_worst_xgb.sort_values(by=['scoreType'])\n",
        "\n",
        "        return best_worst_rf, best_worst_xgb, best_worst\n",
        "\n",
        "\n",
        "    def findBestWorstForAll(self, scoreType: str):\n",
        "        '''\n",
        "        根據所選擇的衡量指標，找出各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        scoreType: | 'RMSE' | 'MAPE' | 'MAE' | 'MAE%' |\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        best, worst\n",
        "        '''\n",
        "\n",
        "        scores = self.best_worst[self.best_worst['scoreType'] == scoreType]   # filter\n",
        "        best = scores.drop(['max_month', 'max_score'], axis=1)\n",
        "        worst = scores.drop(['min_month', 'min_score'], axis=1)\n",
        "\n",
        "        return best, worst\n",
        "\n",
        "\n",
        "    def findBestWorstByModel(self, modelName: str):\n",
        "        '''\n",
        "        根據所選擇的模型，找出不同衡量指標下預測最好和最差的月份。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        modelName: | 'rf' | 'xgb' | 'all' |\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        best_dict: {\"RMSE\", \"MAPE\", \"MAE\", \"MAE%\"}\n",
        "        worst_dict: {\"RMSE\", \"MAPE\", \"MAE\", \"MAE%\"}\n",
        "        '''\n",
        "\n",
        "        if modelName == 'rf':\n",
        "            scoreD = self.best_worst_rf.copy()\n",
        "        elif modelName == 'xgb':\n",
        "            scoreD = self.best_worst_xgb.copy()\n",
        "        elif modelName == 'all':\n",
        "            scoreD = self.best_worst.copy()\n",
        "\n",
        "        best_dict = {}\n",
        "        worst_dict = {}\n",
        "\n",
        "        scoreTypes = ['RMSE', 'MAPE', 'MAE', 'MAE%']\n",
        "        for s in scoreTypes:\n",
        "            scores = scoreD[scoreD['scoreType'] == s]   # filter\n",
        "            best = scores[scores.min_score == scores.min_score.min()]\n",
        "            best = best.drop(['max_month', 'max_score'], axis=1)\n",
        "            best_dict[s] = best\n",
        "            worst = scores[scores.max_score == scores.max_score.max()]\n",
        "            worst = worst.drop(['min_month', 'min_score'], axis=1)\n",
        "            worst_dict[s] = worst\n",
        "\n",
        "        return best_dict, worst_dict\n"
      ],
      "metadata": {
        "id": "9rl8dPOYPHwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.2 RNN & LSTM**\n",
        "\n",
        "2023.04.14"
      ],
      "metadata": {
        "id": "FPIncKPubeBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BestWorstModelNN():\n",
        "    '''\n",
        "    找出最好和最差模型。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    best_rnn, worst_rnn: dict\n",
        "        RNN 在各個衡量指標下最好和最差的模型。\n",
        "    best_lstm, worst_lstm: dict\n",
        "        LSTM 在各個衡量指標下最好和最差的模型。\n",
        "    best_all, worst_all: dict\n",
        "        所有模型中，在各個衡量指標下最好和最差的模型。\n",
        "    ----------\n",
        "    best_worst_rnn, best_worst_lstm: pd.DataFrame\n",
        "        各資料處理方式中，預測最好和最差的月份。\n",
        "    best_worst: pd.DataFrame\n",
        "        各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "\n",
        "    Methods\n",
        "    ----------\n",
        "    findBestWorstForAll(scoreType: str): \n",
        "        根據所選擇的衡量指標，找出各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, score_rnn: pd.DataFrame, score_lstm: pd.DataFrame):\n",
        "        self.score_rnn = score_rnn\n",
        "        self.score_lstm = score_lstm\n",
        "        self.best_worst_rnn, self.best_worst_lstm, self.best_worst = self.createBestWorstForAll()\n",
        "        self.best_rnn, self.worst_rnn = self.findBestWorstByModel('rnn')\n",
        "        self.best_lstm, self.worst_lstm = self.findBestWorstByModel('lstm')\n",
        "        self.best_all, self.worst_all = self.findBestWorstByModel('all')\n",
        "\n",
        "    def createBestWorstForAll(self):\n",
        "        '''\n",
        "        各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "        '''\n",
        "        best_worst_rnn = pd.DataFrame(columns = ['modelName', 'dataType', 'scoreType', 'min_month', 'min_score', 'max_month', 'max_score'])\n",
        "        best_worst_lstm = pd.DataFrame(columns = ['modelName', 'dataType', 'scoreType', 'min_month', 'min_score', 'max_month', 'max_score'])\n",
        "\n",
        "        # RNN\n",
        "        for colName, colData in self.score_rnn.items():\n",
        "            best_worst_rnn.loc[len(best_worst_rnn)] = ['RNN', colName.split(\"-\")[-1], colName.split(\"-\")[0], colData.idxmin(), colData.min(), colData.idxmax(), colData.max()]\n",
        "        # LSTM\n",
        "        for colName, colData in self.score_lstm.items():\n",
        "            best_worst_lstm.loc[len(best_worst_lstm)] = ['LSTM', colName.split(\"-\")[-1], colName.split(\"-\")[0], colData.idxmin(), colData.min(), colData.idxmax(), colData.max()]\n",
        "        \n",
        "        # All\n",
        "        best_worst = pd.concat([best_worst_rnn, best_worst_lstm])\n",
        "\n",
        "        # Sort by scoreType\n",
        "        best_worst_rnn.sort_values(by=['scoreType'])\n",
        "        best_worst_lstm.sort_values(by=['scoreType'])\n",
        "\n",
        "        return best_worst_rnn, best_worst_lstm, best_worst\n",
        "\n",
        "\n",
        "    def findBestWorstForAll(self, scoreType: str):\n",
        "        '''\n",
        "        根據所選擇的衡量指標，找出各資料處理方式與模型組合中，預測最好和最差的月份。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        scoreType: | 'RMSE' | 'MAPE' | 'MAE' | 'MAE%' |\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        best, worst\n",
        "        '''\n",
        "\n",
        "        scores = self.best_worst[self.best_worst['scoreType'] == scoreType]   # filter\n",
        "        best = scores.drop(['max_month', 'max_score'], axis=1)\n",
        "        worst = scores.drop(['min_month', 'min_score'], axis=1)\n",
        "\n",
        "        return best, worst\n",
        "\n",
        "\n",
        "    def findBestWorstByModel(self, modelName: str):\n",
        "        '''\n",
        "        根據所選擇的模型，找出不同衡量指標下預測最好和最差的月份。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        modelName: | 'rnn' | 'lstm' | 'all' |\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        best_dict: {\"RMSE\", \"MAPE\", \"MAE\", \"MAE%\"}\n",
        "        worst_dict: {\"RMSE\", \"MAPE\", \"MAE\", \"MAE%\"}\n",
        "        '''\n",
        "\n",
        "        if modelName == 'rnn':\n",
        "            scoreD = self.best_worst_rnn.copy()\n",
        "        elif modelName == 'lstm':\n",
        "            scoreD = self.best_worst_lstm.copy()\n",
        "        elif modelName == 'all':\n",
        "            scoreD = self.best_worst.copy()\n",
        "\n",
        "        best_dict = {}\n",
        "        worst_dict = {}\n",
        "\n",
        "        scoreTypes = ['RMSE', 'MAPE', 'MAE', 'MAE%']\n",
        "        for s in scoreTypes:\n",
        "            scores = scoreD[scoreD['scoreType'] == s]   # filter\n",
        "            best = scores[scores.min_score == scores.min_score.min()]\n",
        "            best = best.drop(['max_month', 'max_score'], axis=1)\n",
        "            best_dict[s] = best\n",
        "            worst = scores[scores.max_score == scores.max_score.max()]\n",
        "            worst = worst.drop(['min_month', 'min_score'], axis=1)\n",
        "            worst_dict[s] = worst\n",
        "\n",
        "        return best_dict, worst_dict\n"
      ],
      "metadata": {
        "id": "7gkWR3oubJK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}